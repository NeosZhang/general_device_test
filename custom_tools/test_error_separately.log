/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_BCELoss_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 618, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3122, in binary_cross_entropy
    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-03:22:50.815.748 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:22:50 (PID:1335246, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_BCELoss_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_BCELoss_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_BCELoss_no_batch_dim_mean_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 618, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3122, in binary_cross_entropy
    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-03:23:04.031.861 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:23:04 (PID:1335879, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_BCELoss_no_batch_dim_mean_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_BCELoss_no_batch_dim_mean_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_BCELoss_no_batch_dim_none_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 618, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3122, in binary_cross_entropy
    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-03:23:16.049.924 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:23:16 (PID:1336548, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_BCELoss_no_batch_dim_none_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_BCELoss_no_batch_dim_none_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_BCELoss_no_batch_dim_sum_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 618, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3122, in binary_cross_entropy
    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-03:23:25.777.590 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:23:25 (PID:1337181, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_BCELoss_no_batch_dim_sum_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_BCELoss_no_batch_dim_sum_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_BCELoss_scalar_weights_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 618, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3122, in binary_cross_entropy
    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-03:23:35.555.674 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:23:35 (PID:1337790, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_BCELoss_scalar_weights_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_BCELoss_scalar_weights_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_BCELoss_weights_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 618, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3122, in binary_cross_entropy
    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-03:23:44.557.524 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:23:44 (PID:1338366, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_BCELoss_weights_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_BCELoss_weights_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_BCEWithLogitsLoss_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 725, in forward
    return F.binary_cross_entropy_with_logits(input, target,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3195, in binary_cross_entropy_with_logits
    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)
RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-13-03:23:53.365.239 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:23:53 (PID:1338969, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_BCEWithLogitsLoss_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_BCEWithLogitsLoss_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_BCEWithLogitsLoss_no_batch_dim_mean_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 725, in forward
    return F.binary_cross_entropy_with_logits(input, target,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3195, in binary_cross_entropy_with_logits
    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)
RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-13-03:24:03.088.630 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:24:03 (PID:1339569, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_BCEWithLogitsLoss_no_batch_dim_mean_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.012s

FAILED (errors=1)
Class: TestNN, Method: test_BCEWithLogitsLoss_no_batch_dim_mean_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_BCEWithLogitsLoss_no_batch_dim_none_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 725, in forward
    return F.binary_cross_entropy_with_logits(input, target,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3195, in binary_cross_entropy_with_logits
    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)
RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-13-03:24:12.651.990 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:24:12 (PID:1340169, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_BCEWithLogitsLoss_no_batch_dim_none_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.012s

FAILED (errors=1)
Class: TestNN, Method: test_BCEWithLogitsLoss_no_batch_dim_none_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_BCEWithLogitsLoss_no_batch_dim_sum_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 725, in forward
    return F.binary_cross_entropy_with_logits(input, target,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3195, in binary_cross_entropy_with_logits
    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)
RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-13-03:24:22.629.843 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:24:22 (PID:1340769, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_BCEWithLogitsLoss_no_batch_dim_sum_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_BCEWithLogitsLoss_no_batch_dim_sum_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_BCEWithLogitsLoss_scalar_weights_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 725, in forward
    return F.binary_cross_entropy_with_logits(input, target,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3195, in binary_cross_entropy_with_logits
    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)
RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-13-03:24:32.417.786 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:24:32 (PID:1341369, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_BCEWithLogitsLoss_scalar_weights_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_BCEWithLogitsLoss_scalar_weights_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_BCEWithLogitsLoss_weights_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 725, in forward
    return F.binary_cross_entropy_with_logits(input, target,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3195, in binary_cross_entropy_with_logits
    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)
RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-13-03:24:42.070.629 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:24:42 (PID:1341969, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_BCEWithLogitsLoss_weights_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_BCEWithLogitsLoss_weights_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_2d_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:24:51.789.218 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:24:51 (PID:1342566, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_2d_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.026s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_2d_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_2d_ignore_index_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:25:01.496.795 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:25:01 (PID:1343243, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_2d_ignore_index_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.024s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_2d_ignore_index_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_2d_indices_target_smoothing_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:25:10.138.315 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:25:10 (PID:1343891, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_2d_indices_target_smoothing_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.023s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_2d_indices_target_smoothing_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_2d_indices_target_smoothing_ignore_index_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:25:19.985.977 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:25:19 (PID:1344487, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_2d_indices_target_smoothing_ignore_index_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.024s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_2d_indices_target_smoothing_ignore_index_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_2d_indices_target_smoothing_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:25:29.669.763 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:25:29 (PID:1345086, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_2d_indices_target_smoothing_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.022s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_2d_indices_target_smoothing_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_2d_indices_target_smoothing_weight_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:25:39.596.146 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:25:39 (PID:1345673, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_2d_indices_target_smoothing_weight_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.022s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_2d_indices_target_smoothing_weight_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_2d_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:25:48.446.405 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:25:48 (PID:1346271, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_2d_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.034s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_2d_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_2d_weights_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:25:57.952.158 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:25:57 (PID:1346928, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_2d_weights_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.039s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_2d_weights_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_3d_indices_target_smoothing_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:26:07.808.603 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:26:07 (PID:1347597, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_3d_indices_target_smoothing_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.056s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_3d_indices_target_smoothing_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_3d_indices_target_smoothing_ignore_index_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:26:17.493.941 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:26:17 (PID:1348278, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_3d_indices_target_smoothing_ignore_index_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.025s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_3d_indices_target_smoothing_ignore_index_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:26:28.852.068 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:26:28 (PID:1348941, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.026s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_ignore_index_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:26:40.980.970 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:26:40 (PID:1349670, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_ignore_index_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.027s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_ignore_index_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:26:50.729.573 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:26:50 (PID:1350372, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.020s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_dim_is_3_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:27:00.656.992 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:27:00 (PID:1351004, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_dim_is_3_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.027s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_dim_is_3_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_dim_is_3_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:27:10.465.797 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:27:10 (PID:1351719, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_dim_is_3_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.027s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_dim_is_3_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_higher_dim_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:27:20.474.669 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:27:20 (PID:1352434, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_higher_dim_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.024s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_higher_dim_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_higher_dim_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:27:30.368.721 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:27:30 (PID:1353142, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_higher_dim_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.024s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_higher_dim_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CrossEntropyLoss_weights_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:27:40.338.601 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:27:40 (PID:1353866, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CrossEntropyLoss_weights_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.022s

FAILED (errors=1)
Class: TestNN, Method: test_CrossEntropyLoss_weights_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
E
======================================================================
ERROR: test_KLDivLoss_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 470, in forward
    return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:27:50.057.970 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:27:50 (PID:1354541, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_KLDivLoss_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_KLDivLoss_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
E
======================================================================
ERROR: test_KLDivLoss_log_target_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 470, in forward
    return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:27:59.826.865 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:27:59 (PID:1355170, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_KLDivLoss_log_target_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.012s

FAILED (errors=1)
Class: TestNN, Method: test_KLDivLoss_log_target_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_KLDivLoss_log_target_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 470, in forward
    return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:28:09.702.707 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:28:09 (PID:1355790, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_KLDivLoss_log_target_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_KLDivLoss_log_target_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_KLDivLoss_no_batch_dim_mean_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 470, in forward
    return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:28:20.371.332 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:28:20 (PID:1356850, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_KLDivLoss_no_batch_dim_mean_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_KLDivLoss_no_batch_dim_mean_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_KLDivLoss_no_batch_dim_none_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 470, in forward
    return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:28:29.999.424 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:28:29 (PID:1357756, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_KLDivLoss_no_batch_dim_none_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_KLDivLoss_no_batch_dim_none_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_KLDivLoss_no_batch_dim_sum_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 470, in forward
    return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:28:39.900.060 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:28:39 (PID:1358394, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_KLDivLoss_no_batch_dim_sum_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.012s

FAILED (errors=1)
Class: TestNN, Method: test_KLDivLoss_no_batch_dim_sum_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
E
======================================================================
ERROR: test_KLDivLoss_scalar_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 470, in forward
    return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:28:49.514.063 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:28:49 (PID:1359034, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_KLDivLoss_scalar_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_KLDivLoss_scalar_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
E
======================================================================
ERROR: test_KLDivLoss_scalar_log_target_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 470, in forward
    return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:28:58.568.748 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:28:58 (PID:1359624, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_KLDivLoss_scalar_log_target_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_KLDivLoss_scalar_log_target_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_KLDivLoss_scalar_log_target_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 470, in forward
    return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:29:07.182.923 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:29:07 (PID:1360221, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_KLDivLoss_scalar_log_target_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_KLDivLoss_scalar_log_target_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_KLDivLoss_scalar_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 470, in forward
    return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:29:17.185.314 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:29:17 (PID:1360821, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_KLDivLoss_scalar_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_KLDivLoss_scalar_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_KLDivLoss_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 470, in forward
    return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:29:26.715.255 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:29:26 (PID:1361421, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_KLDivLoss_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_KLDivLoss_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_L1Loss_cuda_cdouble (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7606, in test_cdouble
    test.test_cuda(self, dtype=torch.cdouble, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 101, in forward
    return F.l1_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3298, in l1_loss
    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-03:29:36.655.791 Input dtype should be either floating point or complex dtypes. Got self DT_COMPLEX128 and target DT_COMPLEX128 instead.

[ERROR] 2024-09-13-03:29:36 (PID:1362042, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_L1Loss_cuda_cdouble

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_L1Loss_cuda_cdouble
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_L1Loss_cuda_cfloat (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7603, in test_cfloat
    test.test_cuda(self, dtype=torch.cfloat, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 101, in forward
    return F.l1_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3298, in l1_loss
    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-03:29:46.483.428 Input dtype should be either floating point or complex dtypes. Got self DT_COMPLEX64 and target DT_COMPLEX64 instead.

[ERROR] 2024-09-13-03:29:46 (PID:1362655, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_L1Loss_cuda_cfloat

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_L1Loss_cuda_cfloat
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_L1Loss_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 101, in forward
    return F.l1_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3298, in l1_loss
    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-03:29:59.714.848 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:29:59 (PID:1363255, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_L1Loss_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_L1Loss_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_L1Loss_no_batch_dim_mean_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 101, in forward
    return F.l1_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3298, in l1_loss
    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-03:30:11.366.328 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:30:11 (PID:1363906, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_L1Loss_no_batch_dim_mean_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_L1Loss_no_batch_dim_mean_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_L1Loss_no_batch_dim_none_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 101, in forward
    return F.l1_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3298, in l1_loss
    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-03:30:21.102.394 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:30:21 (PID:1364520, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_L1Loss_no_batch_dim_none_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_L1Loss_no_batch_dim_none_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_L1Loss_no_batch_dim_sum_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 101, in forward
    return F.l1_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3298, in l1_loss
    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-03:30:30.945.798 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:30:30 (PID:1365126, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_L1Loss_no_batch_dim_sum_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_L1Loss_no_batch_dim_sum_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_L1Loss_no_reduce_complex_cuda (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7614, in with_tf32_off
    test.test_cuda(self, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4446, in test_cuda
    gpu_output = test_case._forward(gpu_module, gpu_input_tuple)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 243, in _forward
    return module(*input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 168, in forward
    return fn(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 429, in <lambda>
    lambda i: F.l1_loss(i, t.type_as(i), reduction='none')),
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3298, in l1_loss
    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-03:30:40.876.307 promoteType dtype DT_COMPLEX128 should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:30:40 (PID:1365729, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_L1Loss_no_reduce_complex_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_L1Loss_no_reduce_complex_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_L1Loss_scalar_cuda_cdouble (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7606, in test_cdouble
    test.test_cuda(self, dtype=torch.cdouble, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 101, in forward
    return F.l1_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3298, in l1_loss
    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-03:30:50.983.489 Input dtype should be either floating point or complex dtypes. Got self DT_COMPLEX128 and target DT_COMPLEX128 instead.

[ERROR] 2024-09-13-03:30:50 (PID:1366332, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_L1Loss_scalar_cuda_cdouble

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_L1Loss_scalar_cuda_cdouble
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_L1Loss_scalar_cuda_cfloat (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7603, in test_cfloat
    test.test_cuda(self, dtype=torch.cfloat, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 101, in forward
    return F.l1_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3298, in l1_loss
    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-03:31:00.817.936 Input dtype should be either floating point or complex dtypes. Got self DT_COMPLEX64 and target DT_COMPLEX64 instead.

[ERROR] 2024-09-13-03:31:00 (PID:1366938, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_L1Loss_scalar_cuda_cfloat

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.012s

FAILED (errors=1)
Class: TestNN, Method: test_L1Loss_scalar_cuda_cfloat
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_L1Loss_scalar_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 101, in forward
    return F.l1_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3298, in l1_loss
    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-03:31:10.643.630 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:31:10 (PID:1367534, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_L1Loss_scalar_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNN, Method: test_L1Loss_scalar_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MSELoss_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 535, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3329, in mse_loss
    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-03:31:19.400.756 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.

[ERROR] 2024-09-13-03:31:19 (PID:1368124, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MSELoss_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_MSELoss_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MSELoss_no_batch_dim_mean_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 535, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3329, in mse_loss
    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-03:31:29.324.494 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.

[ERROR] 2024-09-13-03:31:29 (PID:1368727, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MSELoss_no_batch_dim_mean_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_MSELoss_no_batch_dim_mean_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MSELoss_no_batch_dim_none_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 535, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3329, in mse_loss
    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-03:31:51.778.830 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.

[ERROR] 2024-09-13-03:31:51 (PID:1369492, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MSELoss_no_batch_dim_none_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.032s

FAILED (errors=1)
Class: TestNN, Method: test_MSELoss_no_batch_dim_none_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MSELoss_no_batch_dim_sum_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 535, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3329, in mse_loss
    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-03:32:01.622.376 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.

[ERROR] 2024-09-13-03:32:01 (PID:1372812, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MSELoss_no_batch_dim_sum_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_MSELoss_no_batch_dim_sum_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MSELoss_prec_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 535, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3329, in mse_loss
    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-03:32:10.384.686 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.

[ERROR] 2024-09-13-03:32:10 (PID:1373436, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MSELoss_prec_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.072s

FAILED (errors=1)
Class: TestNN, Method: test_MSELoss_prec_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MSELoss_scalar_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 535, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3329, in mse_loss
    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-03:32:20.270.507 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.

[ERROR] 2024-09-13-03:32:20 (PID:1374098, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MSELoss_scalar_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_MSELoss_scalar_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MSELoss_scalar_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 535, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3329, in mse_loss
    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-03:32:30.194.112 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.

[ERROR] 2024-09-13-03:32:30 (PID:1374706, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MSELoss_scalar_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.033s

FAILED (errors=1)
Class: TestNN, Method: test_MSELoss_scalar_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MSELoss_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 535, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3329, in mse_loss
    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-03:32:40.779.424 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.

[ERROR] 2024-09-13-03:32:40 (PID:1375311, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MSELoss_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_MSELoss_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/utils/storage.py:38: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if self.device.type != 'cpu':
E
======================================================================
ERROR: test_MaxUnpool1d_net (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7565, in <lambda>
    add(test_name, lambda self, test=test: test(self))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4360, in __call__
    self._do_test(test_case, module, input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4676, in _do_test
    module(*input_tuple)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7734, in forward
    return self.unpool(*self.pool(input))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 325, in forward
    return F.max_unpool1d(input, indices, self.kernel_size, self.stride,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 953, in max_unpool1d
    return torch._C._nn.max_unpool2d(input.unsqueeze(-1), indices.unsqueeze(-1), output_size).squeeze(-1)
RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-03:32:52.084.508 indices expected scalar type DT_INT64 but found DT_INT8.

[ERROR] 2024-09-13-03:32:52 (PID:1375934, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MaxUnpool1d_net

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.106s

FAILED (errors=1)
Class: TestNN, Method: test_MaxUnpool1d_net
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MaxUnpool1d_net_cuda (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7614, in with_tf32_off
    test.test_cuda(self, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4446, in test_cuda
    gpu_output = test_case._forward(gpu_module, gpu_input_tuple)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 243, in _forward
    return module(*input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7734, in forward
    return self.unpool(*self.pool(input))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 325, in forward
    return F.max_unpool1d(input, indices, self.kernel_size, self.stride,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 953, in max_unpool1d
    return torch._C._nn.max_unpool2d(input.unsqueeze(-1), indices.unsqueeze(-1), output_size).squeeze(-1)
RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-03:33:01.684.891 indices expected scalar type DT_INT64 but found DT_INT8.

[ERROR] 2024-09-13-03:33:01 (PID:1376672, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MaxUnpool1d_net_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.055s

FAILED (errors=1)
Class: TestNN, Method: test_MaxUnpool1d_net_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/utils/storage.py:38: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if self.device.type != 'cpu':
E
======================================================================
ERROR: test_MaxUnpool1d_net_no_batch_dim (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7565, in <lambda>
    add(test_name, lambda self, test=test: test(self))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4360, in __call__
    self._do_test(test_case, module, input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4676, in _do_test
    module(*input_tuple)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7734, in forward
    return self.unpool(*self.pool(input))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 325, in forward
    return F.max_unpool1d(input, indices, self.kernel_size, self.stride,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 953, in max_unpool1d
    return torch._C._nn.max_unpool2d(input.unsqueeze(-1), indices.unsqueeze(-1), output_size).squeeze(-1)
RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-03:33:11.288.728 indices expected scalar type DT_INT64 but found DT_INT8.

[ERROR] 2024-09-13-03:33:11 (PID:1377344, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MaxUnpool1d_net_no_batch_dim

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.258s

FAILED (errors=1)
Class: TestNN, Method: test_MaxUnpool1d_net_no_batch_dim
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MaxUnpool1d_net_no_batch_dim_cuda (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7614, in with_tf32_off
    test.test_cuda(self, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4446, in test_cuda
    gpu_output = test_case._forward(gpu_module, gpu_input_tuple)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 243, in _forward
    return module(*input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7734, in forward
    return self.unpool(*self.pool(input))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 325, in forward
    return F.max_unpool1d(input, indices, self.kernel_size, self.stride,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 953, in max_unpool1d
    return torch._C._nn.max_unpool2d(input.unsqueeze(-1), indices.unsqueeze(-1), output_size).squeeze(-1)
RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-03:33:21.054.165 indices expected scalar type DT_INT64 but found DT_INT8.

[ERROR] 2024-09-13-03:33:21 (PID:1378070, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MaxUnpool1d_net_no_batch_dim_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.057s

FAILED (errors=1)
Class: TestNN, Method: test_MaxUnpool1d_net_no_batch_dim_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/utils/storage.py:38: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if self.device.type != 'cpu':
E
======================================================================
ERROR: test_MaxUnpool2d_net (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7565, in <lambda>
    add(test_name, lambda self, test=test: test(self))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4360, in __call__
    self._do_test(test_case, module, input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4676, in _do_test
    module(*input_tuple)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7734, in forward
    return self.unpool(*self.pool(input))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 412, in forward
    return F.max_unpool2d(input, indices, self.kernel_size, self.stride,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 985, in max_unpool2d
    return torch._C._nn.max_unpool2d(input, indices, output_size)
RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-03:33:31.392.478 indices expected scalar type DT_INT64 but found DT_INT8.

[ERROR] 2024-09-13-03:33:31 (PID:1378771, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MaxUnpool2d_net

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.133s

FAILED (errors=1)
Class: TestNN, Method: test_MaxUnpool2d_net
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MaxUnpool2d_net_cuda (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7614, in with_tf32_off
    test.test_cuda(self, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4446, in test_cuda
    gpu_output = test_case._forward(gpu_module, gpu_input_tuple)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 243, in _forward
    return module(*input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7734, in forward
    return self.unpool(*self.pool(input))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 412, in forward
    return F.max_unpool2d(input, indices, self.kernel_size, self.stride,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 985, in max_unpool2d
    return torch._C._nn.max_unpool2d(input, indices, output_size)
RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-03:33:42.900.358 indices expected scalar type DT_INT64 but found DT_INT8.

[ERROR] 2024-09-13-03:33:42 (PID:1379523, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MaxUnpool2d_net_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.055s

FAILED (errors=1)
Class: TestNN, Method: test_MaxUnpool2d_net_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/utils/storage.py:38: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if self.device.type != 'cpu':
E
======================================================================
ERROR: test_MaxUnpool2d_net_no_batch_dim (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7565, in <lambda>
    add(test_name, lambda self, test=test: test(self))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4360, in __call__
    self._do_test(test_case, module, input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4676, in _do_test
    module(*input_tuple)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7734, in forward
    return self.unpool(*self.pool(input))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 412, in forward
    return F.max_unpool2d(input, indices, self.kernel_size, self.stride,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 985, in max_unpool2d
    return torch._C._nn.max_unpool2d(input, indices, output_size)
RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-03:33:53.981.644 indices expected scalar type DT_INT64 but found DT_INT8.

[ERROR] 2024-09-13-03:33:53 (PID:1380246, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MaxUnpool2d_net_no_batch_dim

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.233s

FAILED (errors=1)
Class: TestNN, Method: test_MaxUnpool2d_net_no_batch_dim
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MaxUnpool2d_net_no_batch_dim_cuda (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7614, in with_tf32_off
    test.test_cuda(self, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4446, in test_cuda
    gpu_output = test_case._forward(gpu_module, gpu_input_tuple)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 243, in _forward
    return module(*input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7734, in forward
    return self.unpool(*self.pool(input))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 412, in forward
    return F.max_unpool2d(input, indices, self.kernel_size, self.stride,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 985, in max_unpool2d
    return torch._C._nn.max_unpool2d(input, indices, output_size)
RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-03:34:03.802.458 indices expected scalar type DT_INT64 but found DT_INT8.

[ERROR] 2024-09-13-03:34:03 (PID:1380966, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MaxUnpool2d_net_no_batch_dim_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.057s

FAILED (errors=1)
Class: TestNN, Method: test_MaxUnpool2d_net_no_batch_dim_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/utils/storage.py:38: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if self.device.type != 'cpu':
EZ9999: Inner Error!
EZ9999: 2024-09-13-03:34:14.977.997  length of x should be 5![FUNC:MaxPool3DInferShape][FILE:nn_pooling_ops.cc][LINE:4453]
        TraceBack (most recent call last):
        Call InferShapeAndType for node:MaxPool3D1(MaxPool3D) failed[FUNC:Infer][FILE:infershape_pass.cc][LINE:120]
        process pass InferShapePass on node:MaxPool3D1 failed, ret:4294967295[FUNC:RunPassesOnNode][FILE:base_pass.cc][LINE:570]
        build graph failed, graph id:0, ret:1343242270[FUNC:BuildModelWithGraphId][FILE:ge_generator.cc][LINE:1615]
        [Build][SingleOpModel]call ge interface generator.BuildSingleOpModel failed. ge result = 1343242270[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]
        [Build][Op]Fail to build op model[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145]
        build op model failed, result = 500002[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145]

E
======================================================================
ERROR: test_MaxUnpool3d_net_no_batch_dim (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7565, in <lambda>
    add(test_name, lambda self, test=test: test(self))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4360, in __call__
    self._do_test(test_case, module, input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4676, in _do_test
    module(*input_tuple)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7734, in forward
    return self.unpool(*self.pool(input))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 244, in forward
    return F.max_pool3d(input, self.kernel_size, self.stride,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/_jit_internal.py", line 486, in fn
    return if_true(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 852, in max_pool3d_with_indices
    return torch._C._nn.max_pool3d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: The Inner error is reported as above.
 Since the operator is called asynchronously, the stacktrace may be inaccurate. If you want to get the accurate stacktrace, pleace set the environment variable ASCEND_LAUNCH_BLOCKING=1.
[ERROR] 2024-09-13-03:34:14 (PID:1381644, Device:0, RankID:-1) ERR00100 PTA call acl api failed

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MaxUnpool3d_net_no_batch_dim

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.207s

FAILED (errors=1)
Class: TestNN, Method: test_MaxUnpool3d_net_no_batch_dim
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
EZ9999: Inner Error!
EZ9999: 2024-09-13-03:34:24.593.304  length of x should be 5![FUNC:MaxPool3DInferShape][FILE:nn_pooling_ops.cc][LINE:4453]
        TraceBack (most recent call last):
        Call InferShapeAndType for node:MaxPool3D1(MaxPool3D) failed[FUNC:Infer][FILE:infershape_pass.cc][LINE:120]
        process pass InferShapePass on node:MaxPool3D1 failed, ret:4294967295[FUNC:RunPassesOnNode][FILE:base_pass.cc][LINE:570]
        build graph failed, graph id:0, ret:1343242270[FUNC:BuildModelWithGraphId][FILE:ge_generator.cc][LINE:1615]
        [Build][SingleOpModel]call ge interface generator.BuildSingleOpModel failed. ge result = 1343242270[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]
        [Build][Op]Fail to build op model[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145]
        build op model failed, result = 500002[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145]

E
======================================================================
ERROR: test_MaxUnpool3d_net_no_batch_dim_cuda (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7614, in with_tf32_off
    test.test_cuda(self, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4446, in test_cuda
    gpu_output = test_case._forward(gpu_module, gpu_input_tuple)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 243, in _forward
    return module(*input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7734, in forward
    return self.unpool(*self.pool(input))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 244, in forward
    return F.max_pool3d(input, self.kernel_size, self.stride,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/_jit_internal.py", line 486, in fn
    return if_true(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 852, in max_pool3d_with_indices
    return torch._C._nn.max_pool3d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: The Inner error is reported as above.
 Since the operator is called asynchronously, the stacktrace may be inaccurate. If you want to get the accurate stacktrace, pleace set the environment variable ASCEND_LAUNCH_BLOCKING=1.
[ERROR] 2024-09-13-03:34:24 (PID:1382388, Device:0, RankID:-1) ERR00100 PTA call acl api failed

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MaxUnpool3d_net_no_batch_dim_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.057s

FAILED (errors=1)
Class: TestNN, Method: test_MaxUnpool3d_net_no_batch_dim_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelMarginLoss_1d_cuda_bfloat16 (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7598, in test_bfloat16
    test.test_cuda(self, dtype=torch.bfloat16, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 852, in forward
    return F.multilabel_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3424, in multilabel_margin_loss
    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-03:34:34.593.361 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:34:34 (PID:1383039, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelMarginLoss_1d_cuda_bfloat16

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelMarginLoss_1d_cuda_bfloat16
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelMarginLoss_1d_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 852, in forward
    return F.multilabel_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3424, in multilabel_margin_loss
    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-03:34:44.270.362 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:34:44 (PID:1383642, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelMarginLoss_1d_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelMarginLoss_1d_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelMarginLoss_1d_sum_reduction_cuda_bfloat16 (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7598, in test_bfloat16
    test.test_cuda(self, dtype=torch.bfloat16, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 852, in forward
    return F.multilabel_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3424, in multilabel_margin_loss
    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-03:34:54.026.963 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:34:54 (PID:1384298, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelMarginLoss_1d_sum_reduction_cuda_bfloat16

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelMarginLoss_1d_sum_reduction_cuda_bfloat16
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelMarginLoss_1d_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 852, in forward
    return F.multilabel_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3424, in multilabel_margin_loss
    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-03:35:03.767.511 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:35:03 (PID:1384930, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelMarginLoss_1d_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelMarginLoss_1d_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelMarginLoss_cuda_bfloat16 (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7598, in test_bfloat16
    test.test_cuda(self, dtype=torch.bfloat16, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 852, in forward
    return F.multilabel_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3424, in multilabel_margin_loss
    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-03:35:13.549.561 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:35:13 (PID:1385623, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelMarginLoss_cuda_bfloat16

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelMarginLoss_cuda_bfloat16
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelMarginLoss_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 852, in forward
    return F.multilabel_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3424, in multilabel_margin_loss
    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-03:35:22.619.039 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:35:22 (PID:1386228, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelMarginLoss_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelMarginLoss_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelMarginLoss_no_batch_dim_mean_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 852, in forward
    return F.multilabel_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3424, in multilabel_margin_loss
    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-03:35:32.173.172 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:35:32 (PID:1386923, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelMarginLoss_no_batch_dim_mean_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelMarginLoss_no_batch_dim_mean_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelMarginLoss_no_batch_dim_none_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 852, in forward
    return F.multilabel_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3424, in multilabel_margin_loss
    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-03:35:41.960.845 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:35:41 (PID:1387554, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelMarginLoss_no_batch_dim_none_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelMarginLoss_no_batch_dim_none_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelMarginLoss_no_batch_dim_sum_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 852, in forward
    return F.multilabel_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3424, in multilabel_margin_loss
    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-03:35:52.071.561 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:35:52 (PID:1388229, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelMarginLoss_no_batch_dim_sum_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelMarginLoss_no_batch_dim_sum_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelMarginLoss_sum_reduction_cuda_bfloat16 (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7598, in test_bfloat16
    test.test_cuda(self, dtype=torch.bfloat16, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 852, in forward
    return F.multilabel_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3424, in multilabel_margin_loss
    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-03:36:01.655.989 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:36:01 (PID:1388914, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelMarginLoss_sum_reduction_cuda_bfloat16

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelMarginLoss_sum_reduction_cuda_bfloat16
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelMarginLoss_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 852, in forward
    return F.multilabel_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3424, in multilabel_margin_loss
    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-03:36:10.601.525 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:36:10 (PID:1389549, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelMarginLoss_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelMarginLoss_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelSoftMarginLoss_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1228, in forward
    return F.multilabel_soft_margin_loss(input, target, weight=self.weight, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3475, in multilabel_soft_margin_loss
    loss = -(target * logsigmoid(input) + (1 - target) * logsigmoid(-input))
RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-03:36:20.245.498 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:36:20 (PID:1390188, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelSoftMarginLoss_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.019s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelSoftMarginLoss_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelSoftMarginLoss_no_batch_dim_mean_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1228, in forward
    return F.multilabel_soft_margin_loss(input, target, weight=self.weight, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3475, in multilabel_soft_margin_loss
    loss = -(target * logsigmoid(input) + (1 - target) * logsigmoid(-input))
RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-03:36:30.029.683 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:36:30 (PID:1390889, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelSoftMarginLoss_no_batch_dim_mean_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelSoftMarginLoss_no_batch_dim_mean_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelSoftMarginLoss_no_batch_dim_none_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1228, in forward
    return F.multilabel_soft_margin_loss(input, target, weight=self.weight, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3475, in multilabel_soft_margin_loss
    loss = -(target * logsigmoid(input) + (1 - target) * logsigmoid(-input))
RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-03:36:39.959.761 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:36:39 (PID:1391557, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelSoftMarginLoss_no_batch_dim_none_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.017s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelSoftMarginLoss_no_batch_dim_none_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelSoftMarginLoss_no_batch_dim_sum_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1228, in forward
    return F.multilabel_soft_margin_loss(input, target, weight=self.weight, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3475, in multilabel_soft_margin_loss
    loss = -(target * logsigmoid(input) + (1 - target) * logsigmoid(-input))
RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-03:36:49.683.766 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:36:49 (PID:1392240, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelSoftMarginLoss_no_batch_dim_sum_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelSoftMarginLoss_no_batch_dim_sum_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelSoftMarginLoss_weights_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1228, in forward
    return F.multilabel_soft_margin_loss(input, target, weight=self.weight, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3475, in multilabel_soft_margin_loss
    loss = -(target * logsigmoid(input) + (1 - target) * logsigmoid(-input))
RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-03:37:00.332.126 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:37:00 (PID:1392920, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelSoftMarginLoss_weights_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.022s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelSoftMarginLoss_weights_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_MultiLabelSoftMarginLoss_weights_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1228, in forward
    return F.multilabel_soft_margin_loss(input, target, weight=self.weight, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3475, in multilabel_soft_margin_loss
    loss = -(target * logsigmoid(input) + (1 - target) * logsigmoid(-input))
RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-03:37:11.653.179 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:37:11 (PID:1393598, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_MultiLabelSoftMarginLoss_weights_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.019s

FAILED (errors=1)
Class: TestNN, Method: test_MultiLabelSoftMarginLoss_weights_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_2d_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:37:20.730.250 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:37:20 (PID:1394281, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_2d_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_2d_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_2d_ignore_index_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:37:29.425.965 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:37:29 (PID:1394875, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_2d_ignore_index_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.030s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_2d_ignore_index_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_2d_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:37:39.476.260 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:37:39 (PID:1395475, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_2d_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_2d_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_2d_weights_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:37:49.266.479 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:37:49 (PID:1396109, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_2d_weights_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_2d_weights_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:37:59.264.173 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:37:59 (PID:1396747, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.020s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_dim_is_3_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:38:08.909.680 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:38:08 (PID:1397380, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_dim_is_3_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.019s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_dim_is_3_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_dim_is_3_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:38:18.683.127 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:38:18 (PID:1398032, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_dim_is_3_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.017s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_dim_is_3_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_higher_dim_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:38:27.419.251 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:38:27 (PID:1398637, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_higher_dim_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_higher_dim_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_higher_dim_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-03:38:37.344.995 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:38:37 (PID:1399241, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_higher_dim_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_higher_dim_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_ignore_index_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:38:46.902.280 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:38:46 (PID:1399868, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_ignore_index_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_ignore_index_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_no_batch_dim_mean_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:38:56.732.517 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:38:56 (PID:1400462, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_no_batch_dim_mean_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_no_batch_dim_mean_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_no_batch_dim_none_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:39:05.786.670 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:39:05 (PID:1401056, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_no_batch_dim_none_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.019s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_no_batch_dim_none_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_no_batch_dim_sum_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:39:15.464.174 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:39:15 (PID:1401659, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_no_batch_dim_sum_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_no_batch_dim_sum_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:39:25.395.058 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:39:25 (PID:1402247, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.019s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_weights_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:39:35.288.801 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:39:35 (PID:1402846, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_weights_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_weights_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_weights_ignore_index_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:39:45.269.258 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:39:45 (PID:1403445, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_weights_ignore_index_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_weights_ignore_index_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_NLLLoss_weights_ignore_index_neg_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2729, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:39:54.898.592 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:39:54 (PID:1404044, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_NLLLoss_weights_ignore_index_neg_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_NLLLoss_weights_ignore_index_neg_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_PoissonNLLLoss_full_loss_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 297, in forward
    return F.poisson_nll_loss(log_input, target, log_input=self.log_input, full=self.full,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2793, in poisson_nll_loss
    ret = torch.poisson_nll_loss(input, target, log_input, full, eps, _Reduction.get_enum(reduction))
RuntimeError: call aclnnInplaceMaskedFillScalar failed, detail:EZ1001: 2024-09-13-03:40:04.671.555 selfRef not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT8,DT_BOOL,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:40:04 (PID:1404643, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_PoissonNLLLoss_full_loss_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.020s

FAILED (errors=1)
Class: TestNN, Method: test_PoissonNLLLoss_full_loss_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_PoissonNLLLoss_full_loss_no_log_input_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 297, in forward
    return F.poisson_nll_loss(log_input, target, log_input=self.log_input, full=self.full,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2793, in poisson_nll_loss
    ret = torch.poisson_nll_loss(input, target, log_input, full, eps, _Reduction.get_enum(reduction))
RuntimeError: call aclnnInplaceMaskedFillScalar failed, detail:EZ1001: 2024-09-13-03:40:13.550.283 selfRef not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT8,DT_BOOL,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:40:13 (PID:1405227, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_PoissonNLLLoss_full_loss_no_log_input_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.020s

FAILED (errors=1)
Class: TestNN, Method: test_PoissonNLLLoss_full_loss_no_log_input_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_RNN_change_dropout (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 4810, in test_RNN_change_dropout
    output1, hy1 = rnn(input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 557, in forward
    result = _VF.rnn_relu(input, hx, self._flat_weights, self.bias, self.num_layers,
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-03:40:23.497.241 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:40:23 (PID:1405821, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_RNN_change_dropout

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.019s

FAILED (errors=1)
Class: TestNN, Method: test_RNN_change_dropout
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_RNN_cpu_vs_cudnn_no_dropout (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 4618, in test_RNN_cpu_vs_cudnn_no_dropout
    self._test_RNN_cpu_vs_cudnn(0, dtype)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 4536, in _test_RNN_cpu_vs_cudnn
    outputs_gpu = forward_backward(
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 4446, in forward_backward
    output, hy = rnn(input, hx)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 562, in forward
    result = _VF.rnn_tanh(input, batch_sizes, hx, self._flat_weights, self.bias,
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-03:40:36.637.949 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:40:36 (PID:1406415, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_RNN_cpu_vs_cudnn_no_dropout

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.021s

FAILED (errors=1)
Class: TestNN, Method: test_RNN_cpu_vs_cudnn_no_dropout
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_RNN_cpu_vs_cudnn_with_dropout (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 4623, in test_RNN_cpu_vs_cudnn_with_dropout
    self._test_RNN_cpu_vs_cudnn(1)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 4536, in _test_RNN_cpu_vs_cudnn
    outputs_gpu = forward_backward(
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 4446, in forward_backward
    output, hy = rnn(input, hx)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 562, in forward
    result = _VF.rnn_tanh(input, batch_sizes, hx, self._flat_weights, self.bias,
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-03:40:46.062.767 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:40:46 (PID:1407043, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_RNN_cpu_vs_cudnn_with_dropout

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.017s

FAILED (errors=1)
Class: TestNN, Method: test_RNN_cpu_vs_cudnn_with_dropout
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_RNN_dropout (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 4706, in test_RNN_dropout
    output, hy = rnn(input, hx)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 557, in forward
    result = _VF.rnn_relu(input, hx, self._flat_weights, self.bias, self.num_layers,
RuntimeError: call aclnnMatmul failed, detail:EZ1001: 2024-09-13-03:40:55.812.174 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:40:55 (PID:1407648, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_RNN_dropout

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.037s

FAILED (errors=1)
Class: TestNN, Method: test_RNN_dropout
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SmoothL1Loss_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 933, in forward
    return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3237, in smooth_l1_loss
    return torch._C._nn.smooth_l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), beta)
RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-03:41:05.710.156 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:41:05 (PID:1408251, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SmoothL1Loss_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_SmoothL1Loss_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SmoothL1Loss_no_batch_dim_mean_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 933, in forward
    return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3237, in smooth_l1_loss
    return torch._C._nn.smooth_l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), beta)
RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-03:41:15.399.455 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:41:15 (PID:1408842, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SmoothL1Loss_no_batch_dim_mean_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_SmoothL1Loss_no_batch_dim_mean_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SmoothL1Loss_no_batch_dim_none_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 933, in forward
    return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3237, in smooth_l1_loss
    return torch._C._nn.smooth_l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), beta)
RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-03:41:25.267.408 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:41:25 (PID:1409438, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SmoothL1Loss_no_batch_dim_none_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_SmoothL1Loss_no_batch_dim_none_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SmoothL1Loss_no_batch_dim_sum_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 933, in forward
    return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3237, in smooth_l1_loss
    return torch._C._nn.smooth_l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), beta)
RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-03:41:35.079.501 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:41:35 (PID:1410037, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SmoothL1Loss_no_batch_dim_sum_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_SmoothL1Loss_no_batch_dim_sum_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SmoothL1Loss_scalar_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 933, in forward
    return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3237, in smooth_l1_loss
    return torch._C._nn.smooth_l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), beta)
RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-03:41:45.151.160 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:41:45 (PID:1410636, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SmoothL1Loss_scalar_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_SmoothL1Loss_scalar_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SmoothL1Loss_scalar_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 933, in forward
    return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3237, in smooth_l1_loss
    return torch._C._nn.smooth_l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), beta)
RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-03:41:54.779.145 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:41:54 (PID:1411235, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SmoothL1Loss_scalar_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_SmoothL1Loss_scalar_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SmoothL1Loss_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 933, in forward
    return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3237, in smooth_l1_loss
    return torch._C._nn.smooth_l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), beta)
RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-03:42:03.854.566 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:42:03 (PID:1411819, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SmoothL1Loss_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_SmoothL1Loss_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SoftMarginLoss_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1034, in forward
    return F.soft_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3446, in soft_margin_loss
    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-03:42:13.652.375 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:42:13 (PID:1412413, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SoftMarginLoss_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_SoftMarginLoss_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SoftMarginLoss_no_batch_dim_mean_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1034, in forward
    return F.soft_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3446, in soft_margin_loss
    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-03:42:23.439.197 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:42:23 (PID:1413007, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SoftMarginLoss_no_batch_dim_mean_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_SoftMarginLoss_no_batch_dim_mean_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SoftMarginLoss_no_batch_dim_mean_cuda_float (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7588, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.float, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1034, in forward
    return F.soft_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3446, in soft_margin_loss
    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-03:42:33.371.726 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:42:33 (PID:1413601, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SoftMarginLoss_no_batch_dim_mean_cuda_float

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_SoftMarginLoss_no_batch_dim_mean_cuda_float
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SoftMarginLoss_no_batch_dim_mean_cuda_half (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7593, in test_half
    test.test_cuda(self, dtype=torch.half, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1034, in forward
    return F.soft_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3446, in soft_margin_loss
    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-03:42:43.205.086 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:42:43 (PID:1414195, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SoftMarginLoss_no_batch_dim_mean_cuda_half

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_SoftMarginLoss_no_batch_dim_mean_cuda_half
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SoftMarginLoss_no_batch_dim_none_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1034, in forward
    return F.soft_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3446, in soft_margin_loss
    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-03:42:52.896.562 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:42:52 (PID:1414789, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SoftMarginLoss_no_batch_dim_none_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_SoftMarginLoss_no_batch_dim_none_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SoftMarginLoss_no_batch_dim_none_cuda_float (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7588, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.float, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1034, in forward
    return F.soft_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3446, in soft_margin_loss
    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-03:43:02.412.926 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:43:02 (PID:1415449, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SoftMarginLoss_no_batch_dim_none_cuda_float

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.016s

FAILED (errors=1)
Class: TestNN, Method: test_SoftMarginLoss_no_batch_dim_none_cuda_float
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SoftMarginLoss_no_batch_dim_none_cuda_half (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7593, in test_half
    test.test_cuda(self, dtype=torch.half, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1034, in forward
    return F.soft_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3446, in soft_margin_loss
    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-03:43:12.089.582 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:43:12 (PID:1416043, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SoftMarginLoss_no_batch_dim_none_cuda_half

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_SoftMarginLoss_no_batch_dim_none_cuda_half
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SoftMarginLoss_no_batch_dim_sum_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1034, in forward
    return F.soft_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3446, in soft_margin_loss
    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-03:43:21.808.790 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:43:21 (PID:1416637, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SoftMarginLoss_no_batch_dim_sum_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_SoftMarginLoss_no_batch_dim_sum_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SoftMarginLoss_no_batch_dim_sum_cuda_float (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7588, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.float, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1034, in forward
    return F.soft_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3446, in soft_margin_loss
    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-03:43:30.643.188 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:43:30 (PID:1417231, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SoftMarginLoss_no_batch_dim_sum_cuda_float

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_SoftMarginLoss_no_batch_dim_sum_cuda_float
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SoftMarginLoss_no_batch_dim_sum_cuda_half (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7593, in test_half
    test.test_cuda(self, dtype=torch.half, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1034, in forward
    return F.soft_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3446, in soft_margin_loss
    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-03:43:39.609.834 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:43:39 (PID:1417819, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SoftMarginLoss_no_batch_dim_sum_cuda_half

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_SoftMarginLoss_no_batch_dim_sum_cuda_half
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_SoftMarginLoss_sum_reduction_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 261, in _forward_criterion
    output = criterion(input, target, *extra_args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1034, in forward
    return F.soft_margin_loss(input, target, reduction=self.reduction)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3446, in soft_margin_loss
    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)
RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-03:43:52.626.954 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:43:52 (PID:1418404, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_SoftMarginLoss_sum_reduction_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.017s

FAILED (errors=1)
Class: TestNN, Method: test_SoftMarginLoss_sum_reduction_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_TripletMarginLoss_no_batch_dim_mean_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 259, in _forward_criterion
    output = criterion(*args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1506, in forward
    return F.triplet_margin_loss(anchor, positive, negative, margin=self.margin, p=self.p,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4623, in triplet_margin_loss
    return torch.triplet_margin_loss(anchor, positive, negative, margin, p, eps, swap, reduction_enum)
RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-03:44:03.518.533 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:44:03 (PID:1419034, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_TripletMarginLoss_no_batch_dim_mean_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.019s

FAILED (errors=1)
Class: TestNN, Method: test_TripletMarginLoss_no_batch_dim_mean_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_TripletMarginLoss_no_batch_dim_none_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 259, in _forward_criterion
    output = criterion(*args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1506, in forward
    return F.triplet_margin_loss(anchor, positive, negative, margin=self.margin, p=self.p,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4623, in triplet_margin_loss
    return torch.triplet_margin_loss(anchor, positive, negative, margin, p, eps, swap, reduction_enum)
RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-03:44:13.458.828 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:44:13 (PID:1419676, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_TripletMarginLoss_no_batch_dim_none_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.019s

FAILED (errors=1)
Class: TestNN, Method: test_TripletMarginLoss_no_batch_dim_none_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_TripletMarginLoss_no_batch_dim_sum_cuda_double (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7590, in <lambda>
    test=test, kwargs=kwargs: test.test_cuda(self, dtype=torch.double, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4825, in test_cuda
    gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 259, in _forward_criterion
    output = criterion(*args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1506, in forward
    return F.triplet_margin_loss(anchor, positive, negative, margin=self.margin, p=self.p,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4623, in triplet_margin_loss
    return torch.triplet_margin_loss(anchor, positive, negative, margin, p, eps, swap, reduction_enum)
RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-03:44:23.321.713 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:44:23 (PID:1420270, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_TripletMarginLoss_no_batch_dim_sum_cuda_double

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.019s

FAILED (errors=1)
Class: TestNN, Method: test_TripletMarginLoss_no_batch_dim_sum_cuda_double
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_affine_grid (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 6579, in test_affine_grid
    out_cuda = F.affine_grid(input_gpu, sz, align_corners=align_corners)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4399, in affine_grid
    return torch.affine_grid_generator(theta, size, align_corners)
RuntimeError: call aclnnAffineGrid failed, detail:EZ1001: 2024-09-13-03:44:33.089.448 theta not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:44:33 (PID:1420864, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_affine_grid

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.011s

FAILED (errors=1)
Class: TestNN, Method: test_affine_grid
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_affine_grid_3d (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 6632, in test_affine_grid_3d
    out_cuda = F.affine_grid(input_gpu, sz, align_corners=align_corners)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4399, in affine_grid
    return torch.affine_grid_generator(theta, size, align_corners)
RuntimeError: call aclnnAffineGrid failed, detail:EZ1001: 2024-09-13-03:44:42.780.090 theta not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:44:42 (PID:1421459, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_affine_grid_3d

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.011s

FAILED (errors=1)
Class: TestNN, Method: test_affine_grid_3d
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.038s

OK
Class: TestNN, Method: test_kl_div_log_softmax_target
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
E
======================================================================
ERROR: test_kl_div_with_diff_type (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 5544, in test_kl_div_with_diff_type
    expected = torch.nn.functional.kl_div(input, target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:45:01.425.852 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:45:01 (PID:1422666, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_kl_div_with_diff_type

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.007s

FAILED (errors=1)
Class: TestNN, Method: test_kl_div_with_diff_type
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
E
======================================================================
ERROR: test_kl_div_with_diff_type_log_target (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 5558, in test_kl_div_with_diff_type_log_target
    expected = torch.nn.functional.kl_div(input, target, log_target=True)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2955, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-03:45:11.281.611 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:45:11 (PID:1423254, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_kl_div_with_diff_type_log_target

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.008s

FAILED (errors=1)
Class: TestNN, Method: test_kl_div_with_diff_type_log_target
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.053s

OK
Class: TestNN, Method: test_layer_norm_grads_with_create_graph_flag
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.100s

OK
Class: TestNN, Method: test_linear_autograd_device_cuda_bias_weightStrided
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_comparison.py:293: UserWarning: AutoNonVariableTypeMode is deprecated and will be removed in 1.10 release. For kernel implementations please use AutoDispatchBelowADInplaceOrView instead, If you are looking for a user facing API to enable running your inference-only workload, please use c10::InferenceMode. Using AutoDispatchBelowADInplaceOrView in user code is under risk of producing silent wrong result in some edge cases. See Note [AutoDispatchBelowAutograd] for more details. (Triggered internally at torch_npu/csrc/aten/common/TensorFactories.cpp:74.)
  abs_diff[matches_flat] = 0
F
======================================================================
FAIL: test_linear_autograd_device_cuda_nobias_weightStrided (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 356, in instantiated_test
    test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 500, in test_wrapper
    return test(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 500, in test_wrapper
    return test(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 6991, in test_linear_autograd
    self.assertEqual(g, ge)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3284, in assertEqual
    raise error_metas.pop()[0].to_error(
AssertionError: Tensor-likes are not close!

Mismatched elements: 9 / 16 (56.2%)
Greatest absolute difference: 0.00021946430206298828 at index (2, 1) (up to 1e-05 allowed)
Greatest relative difference: 0.00014616573753301054 at index (2, 1) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_linear_autograd_device_cuda_nobias_weightStrided

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.136s

FAILED (failures=1)
Class: TestNN, Method: test_linear_autograd_device_cuda_nobias_weightStrided
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_log_softmax_scalar_cuda (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7614, in with_tf32_off
    test.test_cuda(self, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4457, in test_cuda
    gpu_gradInput = test_case._backward(gpu_module, gpu_input_tuple, gpu_output, gpu_gradOutput)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 248, in _backward
    output.backward(grad_output, retain_graph=True, create_graph=create_graph)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: call aclnnLogSoftmaxBackward failed, detail:EZ1001: 2024-09-13-03:45:50.555.604 provided dim 0 not in the range of input size 0.

[ERROR] 2024-09-13-03:45:50 (PID:1425732, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_log_softmax_scalar_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNN, Method: test_log_softmax_scalar_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_pdist (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 5475, in test_pdist
    self.assertTrue(gradcheck(lambda x: F.pdist(x, p), (inp,)))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 5475, in <lambda>
    self.assertTrue(gradcheck(lambda x: F.pdist(x, p), (inp,)))
RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-13-03:46:00.490.014 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-03:46:00 (PID:1426332, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_pdist

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNN, Method: test_pdist
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_pdist_empty_col (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 5492, in test_pdist_empty_col
    self.assertTrue(gradcheck(F.pdist, (inp,)))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-13-03:46:10.458.602 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-03:46:10 (PID:1426917, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_pdist_empty_col

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.010s

FAILED (errors=1)
Class: TestNN, Method: test_pdist_empty_col
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_pdist_empty_row (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 5487, in test_pdist_empty_row
    self.assertTrue(gradcheck(F.pdist, (inp,)))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-13-03:46:20.226.876 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-03:46:20 (PID:1427515, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_pdist_empty_row

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.011s

FAILED (errors=1)
Class: TestNN, Method: test_pdist_empty_row
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::_pdist_backward' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
.
----------------------------------------------------------------------
Ran 1 test in 0.074s

OK
Class: TestNN, Method: test_pdist_large
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_pdist_zeros (test_nn.TestNN)
Test that grad is still valid when dist is 0
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 5482, in test_pdist_zeros
    self.assertTrue(gradcheck(lambda x: F.pdist(x, p), (inp,)))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 5482, in <lambda>
    self.assertTrue(gradcheck(lambda x: F.pdist(x, p), (inp,)))
RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-13-03:46:39.955.974 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-03:46:39 (PID:1428774, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_pdist_zeros

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNN, Method: test_pdist_zeros
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_smoothl1loss_intergral_target (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 5713, in test_smoothl1loss_intergral_target
    input_grad = _input_grad(input.detach().clone().requires_grad_(True),
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 5701, in _input_grad
    output = F.smooth_l1_loss(input, target, reduction=reduction, beta=0.5)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3237, in smooth_l1_loss
    return torch._C._nn.smooth_l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), beta)
RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-03:46:49.687.076 target not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:46:49 (PID:1429370, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_smoothl1loss_intergral_target

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNN, Method: test_smoothl1loss_intergral_target
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_sync_batchnorm_backward_elemt (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 7330, in test_sync_batchnorm_backward_elemt
    grad_output.contiguous(memory_format=a),
RuntimeError: NPU contiguous operator only supportted contiguous memory format.
[ERROR] 2024-09-13-03:46:58 (PID:1429965, Device:0, RankID:-1) ERR01007 OPS feature not supported

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_sync_batchnorm_backward_elemt

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.045s

FAILED (errors=1)
Class: TestNN, Method: test_sync_batchnorm_backward_elemt
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py:3655: UserWarning: AutoNonVariableTypeMode is deprecated and will be removed in 1.10 release. For kernel implementations please use AutoDispatchBelowADInplaceOrView instead, If you are looking for a user facing API to enable running your inference-only workload, please use c10::InferenceMode. Using AutoDispatchBelowADInplaceOrView in user code is under risk of producing silent wrong result in some edge cases. See Note [AutoDispatchBelowAutograd] for more details. (Triggered internally at torch_npu/csrc/aten/common/TensorFactories.cpp:74.)
  key_padding_mask[0, 2] = 1
F
======================================================================
FAIL: test_transformerdecoder (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 3860, in test_transformerdecoder
    torch.testing.assert_close(result, ref_output, rtol=1e-7, atol=1e-5)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1520, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 12 / 24 (50.0%)
Greatest absolute difference: 2.765655517578125e-05 at index (2, 0, 3) (up to 1e-05 allowed)
Greatest relative difference: 0.0005092581850476563 at index (2, 1, 3) (up to 1e-07 allowed)

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_transformerdecoder

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.194s

FAILED (failures=1)
Class: TestNN, Method: test_transformerdecoder
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsampling_not_recompute_scale_factor (test_nn.TestNN)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 6715, in test_upsampling_not_recompute_scale_factor
    out_t = F.interpolate(in_t, scale_factor=scale_factor, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-03:47:20.614.411 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-03:47:20 (PID:1431161, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsampling_not_recompute_scale_factor

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNN, Method: test_upsampling_not_recompute_scale_factor
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
Warning: Device do not support double dtype now, dtype cast repalce with float.
E
======================================================================
ERROR: test_GRU_grad_and_gradgrad_cuda_float64 (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 945, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10785, in test_GRU_grad_and_gradgrad
    self._test_rnn_mod(mod, inp)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10747, in _test_rnn_mod
    gradcheck(gradcheckfunc, inp, check_batched_grad=False)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10743, in flatten_out
    out = mod(inp)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 1100, in forward
    self.check_forward_args(input, hx, batch_sizes)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 270, in check_forward_args
    self.check_input(input, batch_sizes)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 230, in check_input
    raise ValueError(f'input must have the type {self._flat_weights[0].dtype}, got type {input.dtype}')
ValueError: input must have the type torch.float32, got type torch.float64

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_GRU_grad_and_gradgrad_cuda_float64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.011s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_GRU_grad_and_gradgrad_cuda_float64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.046s

OK
Class: TestNNDeviceTypeCUDA, Method: test_GroupNorm_empty_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_GroupNorm_general_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8689, in test_GroupNorm_general
    self._test_GroupNorm_general(device)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8157, in _test_GroupNorm_general
    output = gn(x)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 279, in forward
    return F.group_norm(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2558, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: call aclnnGroupNorm failed, detail:EZ1001: 2024-09-13-03:47:50.589.043 Expected eps to be greater than 0, got 0.000000.

[ERROR] 2024-09-13-03:47:50 (PID:1432970, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_GroupNorm_general_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_GroupNorm_general_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
Warning: Device do not support double dtype now, dtype cast repalce with float.
E
======================================================================
ERROR: test_LSTM_grad_and_gradgrad_cuda_float64 (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 945, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10776, in test_LSTM_grad_and_gradgrad
    self._test_rnn_mod(mod, inp)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10747, in _test_rnn_mod
    gradcheck(gradcheckfunc, inp, check_batched_grad=False)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10743, in flatten_out
    out = mod(inp)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/utils/module.py", line 156, in lstm_forward
    self.check_forward_args(input1, hx, batch_sizes)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 790, in check_forward_args
    self.check_input(input, batch_sizes)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 230, in check_input
    raise ValueError(f'input must have the type {self._flat_weights[0].dtype}, got type {input.dtype}')
ValueError: input must have the type torch.float32, got type torch.float64

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_LSTM_grad_and_gradgrad_cuda_float64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.011s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_LSTM_grad_and_gradgrad_cuda_float64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::multi_margin_loss' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::multi_margin_loss_backward' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
.
----------------------------------------------------------------------
Ran 1 test in 0.099s

OK
Class: TestNNDeviceTypeCUDA, Method: test_MarginLoss_warnings_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_ReflectionPad_empty_cuda_complex64 (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9053, in test_ReflectionPad_empty
    (torch.nn.ReflectionPad1d(2), torch.randn(0, 3, 10, device=device, dtype=dtype)),
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py", line 56, in decorated
    return fn(*args, **kwargs)
RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-03:48:19.802.869 self not implemented for DT_COMPLEX64, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:48:19 (PID:1434759, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_ReflectionPad_empty_cuda_complex64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_ReflectionPad_empty_cuda_complex64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_ReplicationPad_empty_cuda_complex128 (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8858, in test_ReplicationPad_empty
    (torch.nn.ReplicationPad1d(3), torch.randn(0, 3, 10, device=device, dtype=dtype)),
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py", line 56, in decorated
    return fn(*args, **kwargs)
RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-03:48:28.534.155 self not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:48:28 (PID:1435416, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_ReplicationPad_empty_cuda_complex128

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_ReplicationPad_empty_cuda_complex128
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_TransformerDecoderLayer_empty_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1157, in wrapper
    fn(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1067, in efail_fn
    return fn(slf, *args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9027, in test_TransformerDecoderLayer_empty
    self._test_module_empty_inputs(decoder_layer, [tgt, memory])
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8264, in _test_module_empty_inputs
    out = module(*inputs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 845, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 854, in _sa_block
    x = self.self_attn(x, x, x,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 5300, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4824, in _in_projection_packed
    proj = linear(q, w, b)
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-03:48:38.194.995 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:48:38 (PID:1436010, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_TransformerDecoderLayer_empty_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.044s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_TransformerDecoderLayer_empty_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_TransformerDecoder_empty_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1157, in wrapper
    fn(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1067, in efail_fn
    return fn(slf, *args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9038, in test_TransformerDecoder_empty
    self._test_module_empty_inputs(transformer_decoder, [tgt, memory])
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8264, in _test_module_empty_inputs
    out = module(*inputs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 459, in forward
    output = mod(output, memory, tgt_mask=tgt_mask,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 845, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 854, in _sa_block
    x = self.self_attn(x, x, x,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 5300, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4824, in _in_projection_packed
    proj = linear(q, w, b)
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-03:48:48.277.106 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:48:48 (PID:1436604, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_TransformerDecoder_empty_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.076s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_TransformerDecoder_empty_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_TransformerEncoderLayer_empty_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1157, in wrapper
    fn(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1067, in efail_fn
    return fn(slf, *args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9007, in test_TransformerEncoderLayer_empty
    _test_module_empty_input(self, encoder_layer, input, check_size=False)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4872, in _test_module_empty_input
    out = module(inp)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 706, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 714, in _sa_block
    x = self.self_attn(x, x, x,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 5300, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4824, in _in_projection_packed
    proj = linear(q, w, b)
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-03:48:58.184.945 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:48:58 (PID:1437198, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_TransformerEncoderLayer_empty_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_TransformerEncoderLayer_empty_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_TransformerEncoder_empty_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1157, in wrapper
    fn(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1067, in efail_fn
    return fn(slf, *args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9017, in test_TransformerEncoder_empty
    _test_module_empty_input(self, transformer_encoder, input, check_size=False)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4872, in _test_module_empty_input
    out = module(inp)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 386, in forward
    output = mod(output, src_mask=mask, is_causal=is_causal, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 706, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 714, in _sa_block
    x = self.self_attn(x, x, x,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 5300, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4824, in _in_projection_packed
    proj = linear(q, w, b)
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-03:49:07.881.134 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:49:07 (PID:1437792, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_TransformerEncoder_empty_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.064s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_TransformerEncoder_empty_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py:281: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
E
======================================================================
ERROR: test_Transformer_empty_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1157, in wrapper
    fn(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1067, in efail_fn
    return fn(slf, *args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9047, in test_Transformer_empty
    self._test_module_empty_inputs(transformer_model, [src, tgt])
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8264, in _test_module_empty_inputs
    out = module(*inputs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 204, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 386, in forward
    output = mod(output, src_mask=mask, is_causal=is_causal, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 706, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 714, in _sa_block
    x = self.self_attn(x, x, x,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 5300, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4824, in _in_projection_packed
    proj = linear(q, w, b)
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-03:49:18.702.189 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:49:18 (PID:1438431, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_Transformer_empty_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.954s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_Transformer_empty_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
F
======================================================================
FAIL: test_Unfold_empty_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
RuntimeError: call aclnnIm2col failed, detail:EZ1001: 2024-09-13-03:49:27.959.534 self'dims is invalid, self No.[2] dim is [0].

[ERROR] 2024-09-13-03:49:27 (PID:1439088, Device:0, RankID:-1) ERR01005 OPS internal error

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9170, in test_Unfold_empty
    unfold(inp)
AssertionError: "Expected 3D or 4D" does not match "call aclnnIm2col failed, detail:EZ1001: 2024-09-13-03:49:27.959.534 self'dims is invalid, self No.[2] dim is [0].

[ERROR] 2024-09-13-03:49:27 (PID:1439088, Device:0, RankID:-1) ERR01005 OPS internal error"

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_Unfold_empty_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.045s

FAILED (failures=1)
Class: TestNNDeviceTypeCUDA, Method: test_Unfold_empty_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_batchnorm_grad_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 11078, in test_batchnorm_grad
    self._test_batchnorm_grad(device)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 11074, in _test_batchnorm_grad
    _assertGradAndGradgradChecks(self, F.batch_norm, (input, running_mean, running_var, weight, bias,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4156, in _assertGradAndGradgradChecks
    test_case.assertTrue(gradcheck(apply_fn, inputs, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2478, in batch_norm
    return torch.batch_norm(
RuntimeError: call aclnnBatchNorm failed, detail:EZ1001: 2024-09-13-03:49:37.919.975 input not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:49:37 (PID:1439728, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_batchnorm_grad_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.017s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_batchnorm_grad_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_clip_grad_norm_error_if_nonfinite_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12136, in test_clip_grad_norm_error_if_nonfinite
    run_test_case(norm_type, error_if_nonfinite, scalar, grad_only_one_elem, prefix_finite_grad_param, True)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12131, in run_test_case
    clip_grad_norm_(parameters, 1, norm_type=norm_type, error_if_nonfinite=error_if_nonfinite)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/utils/clip_grad.py", line 55, in clip_grad_norm_
    norms.extend(torch._foreach_norm(grads, norm_type))
RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-03:49:47.497.327 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:49:47 (PID:1440368, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_clip_grad_norm_error_if_nonfinite_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.206s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_clip_grad_norm_error_if_nonfinite_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.108s

OK
Class: TestNNDeviceTypeCUDA, Method: test_clip_grad_norm_foreach_False_norm_type_2_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.098s

OK
Class: TestNNDeviceTypeCUDA, Method: test_clip_grad_norm_foreach_True_norm_type_2_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/utils/module.py:55: UserWarning: Complex modules are a new feature under active development whose design may change, and some modules might not work as expected when using complex tensors as parameters or buffers. 
  warnings.warn(
[W CopyKernelNpu.cpp:31] Warning: copy_d2d_by_memcpy, dst.data_ptr() is null. (function copy_d2d_by_memcpy)
[W CopyKernelNpu.cpp:31] Warning: copy_d2d_by_memcpy, dst.data_ptr() is null. (function copy_d2d_by_memcpy)
E
======================================================================
ERROR: test_conv_empty_input_cuda_complex128 (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8533, in test_conv_empty_input
    help(input2d, conv2d, torch.channels_last)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8520, in help
    ref_out = conv(input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: call aclnnAdd failed, detail:EZ1001: 2024-09-13-03:50:16.924.087 other not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT16,DT_INT8,DT_UINT8,DT_DOUBLE,DT_BOOL,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:50:16 (PID:1442235, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_conv_empty_input_cuda_complex128

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.019s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_conv_empty_input_cuda_complex128
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
Warning: Device do not support double dtype now, dtype cast repalce with float.
E
======================================================================
ERROR: test_cross_entropy_label_smoothing_consistent_index_target_and_probs_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 11877, in test_cross_entropy_label_smoothing_consistent_index_target_and_probs
    output_with_index = loss(input, target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-03:50:26.794.890 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:50:26 (PID:1442838, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_cross_entropy_label_smoothing_consistent_index_target_and_probs_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.058s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_cross_entropy_label_smoothing_consistent_index_target_and_probs_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.077s

OK
Class: TestNNDeviceTypeCUDA, Method: test_cross_entropy_label_smoothing_weight_ignore_indices_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.050s

OK
Class: TestNNDeviceTypeCUDA, Method: test_cross_entropy_loss_index_target_unit_weights_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.057s

OK
Class: TestNNDeviceTypeCUDA, Method: test_cross_entropy_loss_one_hot_target_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_fold_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12023, in test_fold
    gradcheck(func, [x], check_forward_ad=True)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12017, in func
    return F.fold(x, output_size=(4, 5), kernel_size=(2, 2))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4778, in fold
    return torch._C._nn.col2im(
RuntimeError: call aclnnIm2colBackward failed, detail:EZ1001: 2024-09-13-03:51:08.224.553 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-03:51:08 (PID:1445294, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_fold_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_fold_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_hardsigmoid_grad_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 11118, in test_hardsigmoid_grad
    self.assertTrue(gradcheck(F.hardsigmoid, (inputs,)))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2003, in hardsigmoid
    return torch._C._nn.hardsigmoid(input)
RuntimeError: call aclnnHardsigmoid failed, detail:EZ1001: 2024-09-13-03:51:18.213.530 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT32,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:51:18 (PID:1445905, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_hardsigmoid_grad_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_hardsigmoid_grad_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_hardswish_grad_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 11125, in test_hardswish_grad
    self.assertTrue(gradcheck(F.hardswish, (inputs,)))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2115, in hardswish
    return torch._C._nn.hardswish(input)
RuntimeError: call aclnnHardswish failed, detail:EZ1001: 2024-09-13-03:51:27.780.211 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:51:27 (PID:1446541, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_hardswish_grad_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.014s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_hardswish_grad_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.050s

OK
Class: TestNNDeviceTypeCUDA, Method: test_instancenorm_raises_error_for_single_spatial_element_during_training_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_invalid_reduction_strings_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9377, in test_invalid_reduction_strings
    cinput = torch.randn(3, 5, requires_grad=True, device=device, dtype=torch.cfloat)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py", line 56, in decorated
    return fn(*args, **kwargs)
RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-03:51:46.589.673 self not implemented for DT_COMPLEX64, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:51:46 (PID:1447751, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_invalid_reduction_strings_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.016s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_invalid_reduction_strings_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.044s

OK
Class: TestNNDeviceTypeCUDA, Method: test_linear_empty_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.040s

OK
Class: TestNNDeviceTypeCUDA, Method: test_logsigmoid_out_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::_masked_softmax' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
.
----------------------------------------------------------------------
Ran 1 test in 1.122s

OK
Class: TestNNDeviceTypeCUDA, Method: test_masked_softmax_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::_masked_softmax' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
.
----------------------------------------------------------------------
Ran 1 test in 9.618s

OK
Class: TestNNDeviceTypeCUDA, Method: test_masked_softmax_devices_parity_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::_masked_softmax' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::_masked_softmax_backward' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
.
----------------------------------------------------------------------
Ran 1 test in 0.795s

OK
Class: TestNNDeviceTypeCUDA, Method: test_masked_softmax_forward_with_nans_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::_masked_softmax' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::_masked_softmax_backward' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
.
----------------------------------------------------------------------
Ran 1 test in 1.861s

OK
Class: TestNNDeviceTypeCUDA, Method: test_masked_softmax_grad_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::_masked_softmax' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
.
----------------------------------------------------------------------
Ran 1 test in 4.177s

OK
Class: TestNNDeviceTypeCUDA, Method: test_masked_softmax_mask_types_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_module_to_empty_cuda_float64 (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 945, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12399, in test_module_to_empty
    m(input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12390, in forward
    return x @ self.weight
RuntimeError: call aclnnMatmul failed, detail:EZ1001: 2024-09-13-03:53:22.511.009 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:53:22 (PID:1453164, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_module_to_empty_cuda_float64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_module_to_empty_cuda_float64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.050s

OK
Class: TestNNDeviceTypeCUDA, Method: test_nll_loss_all_ignored_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.056s

OK
Class: TestNNDeviceTypeCUDA, Method: test_nll_loss_byte_target_matches_long_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.052s

OK
Class: TestNNDeviceTypeCUDA, Method: test_nll_loss_empty_tensor_reduction_mean_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.041s

OK
Class: TestNNDeviceTypeCUDA, Method: test_nll_loss_empty_tensor_reduction_none_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.053s

OK
Class: TestNNDeviceTypeCUDA, Method: test_nll_loss_empty_tensor_reduction_sum_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.049s

OK
Class: TestNNDeviceTypeCUDA, Method: test_nll_loss_out_of_bounds_ignore_index_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.050s

OK
Class: TestNNDeviceTypeCUDA, Method: test_nll_loss_total_weight_is_zero_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.009s

OK
Class: TestNNDeviceTypeCUDA, Method: test_nn_empty_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.056s

OK
Class: TestNNDeviceTypeCUDA, Method: test_nn_scalars_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.079s

OK
Class: TestNNDeviceTypeCUDA, Method: test_nn_scalars_reductions_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.048s

OK
Class: TestNNDeviceTypeCUDA, Method: test_nonlinearity_propagate_nan_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_pad_cuda_complex128 (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8827, in test_pad
    inputs = torch.randn(1, 1, 4, device=device, dtype=dtype, requires_grad=True)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py", line 56, in decorated
    return fn(*args, **kwargs)
RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-03:55:21.309.726 self not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:55:21 (PID:1460452, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_pad_cuda_complex128

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.015s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_pad_cuda_complex128
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::huber_loss' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
.
----------------------------------------------------------------------
Ran 1 test in 0.058s

OK
Class: TestNNDeviceTypeCUDA, Method: test_smooth_l1_loss_vs_huber_loss_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.046s

OK
Class: TestNNDeviceTypeCUDA, Method: test_smoothl1loss_backward_zero_beta_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_softplus_low_threshold_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12213, in test_softplus_low_threshold
    output = model(input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 840, in forward
    return F.softplus(input, self.beta, self.threshold)
RuntimeError: call aclnnSoftplus failed, detail:EZ1001: 2024-09-13-03:55:50.972.423 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:55:50 (PID:1462272, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_softplus_low_threshold_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_softplus_low_threshold_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.040s

OK
Class: TestNNDeviceTypeCUDA, Method: test_threshold_inplace_overlap_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_transformerencoderlayer_cuda_float64 (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12631, in test_transformerencoderlayer
    _test(batch_first=batch_first, training=training, atol=atol, rtol=rtol)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12490, in _test
    result = model(encoder_input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 706, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 714, in _sa_block
    x = self.self_attn(x, x, x,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 5300, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4824, in _in_projection_packed
    proj = linear(q, w, b)
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-03:56:10.518.262 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:56:10 (PID:1463485, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_transformerencoderlayer_cuda_float64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.020s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_transformerencoderlayer_cuda_float64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_triplet_margin_with_distance_loss_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12344, in test_triplet_margin_with_distance_loss
    self.assertTrue(gradcheck(lambda a, p, n: F.triplet_margin_with_distance_loss(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12344, in <lambda>
    self.assertTrue(gradcheck(lambda a, p, n: F.triplet_margin_with_distance_loss(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4676, in triplet_margin_with_distance_loss
    dist_pos = distance_function(anchor, positive)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/distance.py", line 53, in forward
    return F.pairwise_distance(x1, x2, self.norm, self.eps, self.keepdim)
RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-03:56:20.537.525 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:56:20 (PID:1464077, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_triplet_margin_with_distance_loss_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.017s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_triplet_margin_with_distance_loss_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_triplet_margin_with_distance_loss_default_parity_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12303, in test_triplet_margin_with_distance_loss_default_parity
    expected = F.triplet_margin_loss(anchor, positive, negative, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4623, in triplet_margin_loss
    return torch.triplet_margin_loss(anchor, positive, negative, margin, p, eps, swap, reduction_enum)
RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-03:56:30.154.573 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:56:30 (PID:1464682, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_triplet_margin_with_distance_loss_default_parity_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.018s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_triplet_margin_with_distance_loss_default_parity_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9865, in test_upsamplingBiMode2d
    out_t = F.interpolate(in_t, scale_factor=scale_factor, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-03:56:39.969.532 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-03:56:39 (PID:1465287, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.017s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9865, in test_upsamplingBiMode2d
    out_t = F.interpolate(in_t, scale_factor=scale_factor, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-03:56:48.511.694 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-03:56:48 (PID:1465877, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.017s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bicubic_float64_cuda_float64 (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9941, in test_upsamplingBiMode2d_nonsupported_dtypes
    _ = F.interpolate(x, (12, 12), mode=mode, antialias=antialias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-03:56:58.144.739 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-03:56:58 (PID:1466477, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bicubic_float64_cuda_float64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.017s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bicubic_float64_cuda_float64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bicubic_float64_cuda_float64 (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9941, in test_upsamplingBiMode2d_nonsupported_dtypes
    _ = F.interpolate(x, (12, 12), mode=mode, antialias=antialias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-03:57:08.059.124 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-03:57:08 (PID:1467077, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bicubic_float64_cuda_float64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.017s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bicubic_float64_cuda_float64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.044s

OK
Class: TestNNDeviceTypeCUDA, Method: test_upsamplingBicubic2d_correctness_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest_cuda (test_nn.TestNNDeviceTypeCUDA)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9761, in test_upsamplingNearest3d
    out_uint8_t = m(in_uint8_t)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/upsampling.py", line 156, in forward
    return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3985, in interpolate
    return torch._C._nn.upsample_nearest3d(input, output_size, scale_factors)
RuntimeError: call aclnnUpsampleNearest3d failed, detail:EZ1001: 2024-09-13-03:57:30.921.550 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_DOUBLE,].

[ERROR] 2024-09-13-03:57:30 (PID:1468340, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest_cuda

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.043s

FAILED (errors=1)
Class: TestNNDeviceTypeCUDA, Method: test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest_cuda
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_False_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10954, in test_CTCLoss_no_batch_dim
    args = self._CTCLoss_gen_losses(device, input_length, vocab_size, target_length, reduction, use_module_form)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10935, in _CTCLoss_gen_losses
    losses_no_bd.append(ctc_loss(log_probs_no_bd_refs[0], targets_no_bd,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2656, in ctc_loss
    return torch.ctc_loss(
RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-13-03:57:40.618.770 DimNum of logProbs [2] must equal 3.

[ERROR] 2024-09-13-03:57:40 (PID:1468967, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_False_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_False_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_True_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10954, in test_CTCLoss_no_batch_dim
    args = self._CTCLoss_gen_losses(device, input_length, vocab_size, target_length, reduction, use_module_form)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10935, in _CTCLoss_gen_losses
    losses_no_bd.append(ctc_loss(log_probs_no_bd_refs[0], targets_no_bd,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1770, in forward
    return F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2656, in ctc_loss
    return torch.ctc_loss(
RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-13-03:57:50.513.309 DimNum of logProbs [2] must equal 3.

[ERROR] 2024-09-13-03:57:50 (PID:1469572, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_True_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_True_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CTCLoss_no_batch_dim_reduction_none_use_module_form_False_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10954, in test_CTCLoss_no_batch_dim
    args = self._CTCLoss_gen_losses(device, input_length, vocab_size, target_length, reduction, use_module_form)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10935, in _CTCLoss_gen_losses
    losses_no_bd.append(ctc_loss(log_probs_no_bd_refs[0], targets_no_bd,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2656, in ctc_loss
    return torch.ctc_loss(
RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-13-03:58:00.070.852 DimNum of logProbs [2] must equal 3.

[ERROR] 2024-09-13-03:58:00 (PID:1470177, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CTCLoss_no_batch_dim_reduction_none_use_module_form_False_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.040s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_CTCLoss_no_batch_dim_reduction_none_use_module_form_False_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CTCLoss_no_batch_dim_reduction_none_use_module_form_True_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10954, in test_CTCLoss_no_batch_dim
    args = self._CTCLoss_gen_losses(device, input_length, vocab_size, target_length, reduction, use_module_form)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10935, in _CTCLoss_gen_losses
    losses_no_bd.append(ctc_loss(log_probs_no_bd_refs[0], targets_no_bd,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1770, in forward
    return F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2656, in ctc_loss
    return torch.ctc_loss(
RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-13-03:58:09.888.659 DimNum of logProbs [2] must equal 3.

[ERROR] 2024-09-13-03:58:09 (PID:1470782, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CTCLoss_no_batch_dim_reduction_none_use_module_form_True_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.040s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_CTCLoss_no_batch_dim_reduction_none_use_module_form_True_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_False_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10954, in test_CTCLoss_no_batch_dim
    args = self._CTCLoss_gen_losses(device, input_length, vocab_size, target_length, reduction, use_module_form)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10935, in _CTCLoss_gen_losses
    losses_no_bd.append(ctc_loss(log_probs_no_bd_refs[0], targets_no_bd,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2656, in ctc_loss
    return torch.ctc_loss(
RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-13-03:58:18.783.490 DimNum of logProbs [2] must equal 3.

[ERROR] 2024-09-13-03:58:18 (PID:1471369, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_False_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.046s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_False_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_True_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10954, in test_CTCLoss_no_batch_dim
    args = self._CTCLoss_gen_losses(device, input_length, vocab_size, target_length, reduction, use_module_form)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10935, in _CTCLoss_gen_losses
    losses_no_bd.append(ctc_loss(log_probs_no_bd_refs[0], targets_no_bd,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1770, in forward
    return F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2656, in ctc_loss
    return torch.ctc_loss(
RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-13-03:58:28.655.115 DimNum of logProbs [2] must equal 3.

[ERROR] 2024-09-13-03:58:28 (PID:1471969, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_True_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.046s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_True_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
Warning: Device do not support double dtype now, dtype cast repalce with float.
E
======================================================================
ERROR: test_GRU_grad_and_gradgrad_npu_float64 (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 945, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10785, in test_GRU_grad_and_gradgrad
    self._test_rnn_mod(mod, inp)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10747, in _test_rnn_mod
    gradcheck(gradcheckfunc, inp, check_batched_grad=False)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10743, in flatten_out
    out = mod(inp)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 1100, in forward
    self.check_forward_args(input, hx, batch_sizes)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 270, in check_forward_args
    self.check_input(input, batch_sizes)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 230, in check_input
    raise ValueError(f'input must have the type {self._flat_weights[0].dtype}, got type {input.dtype}')
ValueError: input must have the type torch.float32, got type torch.float64

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_GRU_grad_and_gradgrad_npu_float64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.005s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_GRU_grad_and_gradgrad_npu_float64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.041s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_GroupNorm_empty_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_GroupNorm_general_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8689, in test_GroupNorm_general
    self._test_GroupNorm_general(device)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8157, in _test_GroupNorm_general
    output = gn(x)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 279, in forward
    return F.group_norm(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2558, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: call aclnnGroupNorm failed, detail:EZ1001: 2024-09-13-03:58:58.444.119 Expected eps to be greater than 0, got 0.000000.

[ERROR] 2024-09-13-03:58:58 (PID:1473771, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_GroupNorm_general_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.041s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_GroupNorm_general_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
Warning: Device do not support double dtype now, dtype cast repalce with float.
E
======================================================================
ERROR: test_LSTM_grad_and_gradgrad_npu_float64 (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 945, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10776, in test_LSTM_grad_and_gradgrad
    self._test_rnn_mod(mod, inp)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10747, in _test_rnn_mod
    gradcheck(gradcheckfunc, inp, check_batched_grad=False)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10743, in flatten_out
    out = mod(inp)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/utils/module.py", line 156, in lstm_forward
    self.check_forward_args(input1, hx, batch_sizes)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 790, in check_forward_args
    self.check_input(input, batch_sizes)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py", line 230, in check_input
    raise ValueError(f'input must have the type {self._flat_weights[0].dtype}, got type {input.dtype}')
ValueError: input must have the type torch.float32, got type torch.float64

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_LSTM_grad_and_gradgrad_npu_float64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.005s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_LSTM_grad_and_gradgrad_npu_float64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_ReflectionPad_empty_npu_complex64 (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9053, in test_ReflectionPad_empty
    (torch.nn.ReflectionPad1d(2), torch.randn(0, 3, 10, device=device, dtype=dtype)),
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py", line 56, in decorated
    return fn(*args, **kwargs)
RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-03:59:18.133.655 self not implemented for DT_COMPLEX64, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:59:18 (PID:1474971, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_ReflectionPad_empty_npu_complex64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.010s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_ReflectionPad_empty_npu_complex64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_ReplicationPad_empty_npu_complex128 (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8858, in test_ReplicationPad_empty
    (torch.nn.ReplicationPad1d(3), torch.randn(0, 3, 10, device=device, dtype=dtype)),
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py", line 56, in decorated
    return fn(*args, **kwargs)
RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-03:59:27.758.484 self not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:59:27 (PID:1475571, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_ReplicationPad_empty_npu_complex128

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.009s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_ReplicationPad_empty_npu_complex128
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_TransformerDecoderLayer_empty_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1157, in wrapper
    fn(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1067, in efail_fn
    return fn(slf, *args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9027, in test_TransformerDecoderLayer_empty
    self._test_module_empty_inputs(decoder_layer, [tgt, memory])
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8264, in _test_module_empty_inputs
    out = module(*inputs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 845, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 854, in _sa_block
    x = self.self_attn(x, x, x,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 5300, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4824, in _in_projection_packed
    proj = linear(q, w, b)
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-03:59:37.857.546 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:59:37 (PID:1476171, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_TransformerDecoderLayer_empty_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.040s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_TransformerDecoderLayer_empty_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_TransformerDecoder_empty_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1157, in wrapper
    fn(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1067, in efail_fn
    return fn(slf, *args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9038, in test_TransformerDecoder_empty
    self._test_module_empty_inputs(transformer_decoder, [tgt, memory])
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8264, in _test_module_empty_inputs
    out = module(*inputs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 459, in forward
    output = mod(output, memory, tgt_mask=tgt_mask,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 845, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 854, in _sa_block
    x = self.self_attn(x, x, x,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 5300, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4824, in _in_projection_packed
    proj = linear(q, w, b)
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-03:59:47.611.827 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:59:47 (PID:1476771, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_TransformerDecoder_empty_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.067s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_TransformerDecoder_empty_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_TransformerEncoderLayer_empty_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1157, in wrapper
    fn(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1067, in efail_fn
    return fn(slf, *args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9007, in test_TransformerEncoderLayer_empty
    _test_module_empty_input(self, encoder_layer, input, check_size=False)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4872, in _test_module_empty_input
    out = module(inp)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 706, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 714, in _sa_block
    x = self.self_attn(x, x, x,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 5300, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4824, in _in_projection_packed
    proj = linear(q, w, b)
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-03:59:57.470.255 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-03:59:57 (PID:1477371, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_TransformerEncoderLayer_empty_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.034s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_TransformerEncoderLayer_empty_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_TransformerEncoder_empty_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1157, in wrapper
    fn(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1067, in efail_fn
    return fn(slf, *args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9017, in test_TransformerEncoder_empty
    _test_module_empty_input(self, transformer_encoder, input, check_size=False)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_nn.py", line 4872, in _test_module_empty_input
    out = module(inp)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 386, in forward
    output = mod(output, src_mask=mask, is_causal=is_causal, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 706, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 714, in _sa_block
    x = self.self_attn(x, x, x,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 5300, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4824, in _in_projection_packed
    proj = linear(q, w, b)
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-04:00:07.269.202 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:00:07 (PID:1477971, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_TransformerEncoder_empty_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.066s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_TransformerEncoder_empty_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py:281: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
E
======================================================================
ERROR: test_Transformer_empty_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1157, in wrapper
    fn(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1067, in efail_fn
    return fn(slf, *args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9047, in test_Transformer_empty
    self._test_module_empty_inputs(transformer_model, [src, tgt])
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8264, in _test_module_empty_inputs
    out = module(*inputs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 204, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 386, in forward
    output = mod(output, src_mask=mask, is_causal=is_causal, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 706, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 714, in _sa_block
    x = self.self_attn(x, x, x,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 5300, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4824, in _in_projection_packed
    proj = linear(q, w, b)
RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-04:00:17.901.269 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:00:17 (PID:1478571, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_Transformer_empty_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.941s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_Transformer_empty_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
F
======================================================================
FAIL: test_Unfold_empty_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
RuntimeError: call aclnnIm2col failed, detail:EZ1001: 2024-09-13-04:00:27.450.904 self'dims is invalid, self No.[2] dim is [0].

[ERROR] 2024-09-13-04:00:27 (PID:1479234, Device:0, RankID:-1) ERR01005 OPS internal error

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9170, in test_Unfold_empty
    unfold(inp)
AssertionError: "Expected 3D or 4D" does not match "call aclnnIm2col failed, detail:EZ1001: 2024-09-13-04:00:27.450.904 self'dims is invalid, self No.[2] dim is [0].

[ERROR] 2024-09-13-04:00:27 (PID:1479234, Device:0, RankID:-1) ERR01005 OPS internal error"

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_Unfold_empty_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.038s

FAILED (failures=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_Unfold_empty_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_batchnorm_grad_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 11078, in test_batchnorm_grad
    self._test_batchnorm_grad(device)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 11074, in _test_batchnorm_grad
    _assertGradAndGradgradChecks(self, F.batch_norm, (input, running_mean, running_var, weight, bias,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4156, in _assertGradAndGradgradChecks
    test_case.assertTrue(gradcheck(apply_fn, inputs, **kwargs))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2478, in batch_norm
    return torch.batch_norm(
RuntimeError: call aclnnBatchNorm failed, detail:EZ1001: 2024-09-13-04:00:37.300.763 input not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:00:37 (PID:1479835, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_batchnorm_grad_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.011s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_batchnorm_grad_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_clip_grad_norm_error_if_nonfinite_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12136, in test_clip_grad_norm_error_if_nonfinite
    run_test_case(norm_type, error_if_nonfinite, scalar, grad_only_one_elem, prefix_finite_grad_param, True)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12131, in run_test_case
    clip_grad_norm_(parameters, 1, norm_type=norm_type, error_if_nonfinite=error_if_nonfinite)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/utils/clip_grad.py", line 55, in clip_grad_norm_
    norms.extend(torch._foreach_norm(grads, norm_type))
RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-04:00:47.853.314 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:00:47 (PID:1480435, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_clip_grad_norm_error_if_nonfinite_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.225s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_clip_grad_norm_error_if_nonfinite_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.093s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_clip_grad_norm_foreach_False_norm_type_2_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.096s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_clip_grad_norm_foreach_True_norm_type_2_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/utils/module.py:55: UserWarning: Complex modules are a new feature under active development whose design may change, and some modules might not work as expected when using complex tensors as parameters or buffers. 
  warnings.warn(
[W CopyKernelNpu.cpp:31] Warning: copy_d2d_by_memcpy, dst.data_ptr() is null. (function copy_d2d_by_memcpy)
[W CopyKernelNpu.cpp:31] Warning: copy_d2d_by_memcpy, dst.data_ptr() is null. (function copy_d2d_by_memcpy)
E
======================================================================
ERROR: test_conv_empty_input_npu_complex128 (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8533, in test_conv_empty_input
    help(input2d, conv2d, torch.channels_last)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8520, in help
    ref_out = conv(input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: call aclnnAdd failed, detail:EZ1001: 2024-09-13-04:01:19.061.086 other not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT16,DT_INT8,DT_UINT8,DT_DOUBLE,DT_BOOL,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:01:19 (PID:1482317, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_conv_empty_input_npu_complex128

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.013s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_conv_empty_input_npu_complex128
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
Warning: Device do not support double dtype now, dtype cast repalce with float.
E
======================================================================
ERROR: test_cross_entropy_label_smoothing_consistent_index_target_and_probs_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 11877, in test_cross_entropy_label_smoothing_consistent_index_target_and_probs
    output_with_index = loss(input, target)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-04:01:28.983.366 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:01:28 (PID:1482917, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_cross_entropy_label_smoothing_consistent_index_target_and_probs_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.062s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_cross_entropy_label_smoothing_consistent_index_target_and_probs_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.071s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_cross_entropy_label_smoothing_weight_ignore_indices_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.047s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_cross_entropy_loss_index_target_unit_weights_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.055s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_cross_entropy_loss_one_hot_target_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
Warning: Device do not support double dtype now, dtype cast repalce with float.
E
======================================================================
ERROR: test_ctc_loss_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 945, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 11387, in test_ctc_loss
    gradcheck(ctc_after_softmax, [x])
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2080, in _gradcheck_helper
    _gradcheck_real_imag(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1482, in _gradcheck_real_imag
    gradcheck_fn(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1863, in _fast_gradcheck
    all_v, all_u, all_u_dense = _make_vectors(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1786, in _make_vectors
    ur = _vec_from_tensor(inp, g_cpu, True)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1688, in _vec_from_tensor
    vec /= vec.norm()
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/_tensor.py", line 708, in norm
    return torch.norm(self, p, dim, keepdim, dtype=dtype)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/functional.py", line 1595, in norm
    return torch.linalg.vector_norm(input, 2, _dim, keepdim, dtype=dtype)
RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-04:02:08.530.295 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:02:08 (PID:1485318, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_ctc_loss_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.057s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_ctc_loss_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_fold_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12023, in test_fold
    gradcheck(func, [x], check_forward_ad=True)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12017, in func
    return F.fold(x, output_size=(4, 5), kernel_size=(2, 2))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4778, in fold
    return torch._C._nn.col2im(
RuntimeError: call aclnnIm2colBackward failed, detail:EZ1001: 2024-09-13-04:02:18.223.127 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].

[ERROR] 2024-09-13-04:02:18 (PID:1485918, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_fold_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.008s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_fold_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_hardsigmoid_grad_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 11118, in test_hardsigmoid_grad
    self.assertTrue(gradcheck(F.hardsigmoid, (inputs,)))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2003, in hardsigmoid
    return torch._C._nn.hardsigmoid(input)
RuntimeError: call aclnnHardsigmoid failed, detail:EZ1001: 2024-09-13-04:02:28.118.676 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT32,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:02:28 (PID:1486518, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_hardsigmoid_grad_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.009s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_hardsigmoid_grad_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_hardswish_grad_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 11125, in test_hardswish_grad
    self.assertTrue(gradcheck(F.hardswish, (inputs,)))
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 2115, in hardswish
    return torch._C._nn.hardswish(input)
RuntimeError: call aclnnHardswish failed, detail:EZ1001: 2024-09-13-04:02:38.250.226 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:02:38 (PID:1487118, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_hardswish_grad_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.008s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_hardswish_grad_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.043s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_instancenorm_raises_error_for_single_spatial_element_during_training_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_invalid_reduction_strings_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9377, in test_invalid_reduction_strings
    cinput = torch.randn(3, 5, requires_grad=True, device=device, dtype=torch.cfloat)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py", line 56, in decorated
    return fn(*args, **kwargs)
RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-04:02:57.003.029 self not implemented for DT_COMPLEX64, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:02:57 (PID:1488318, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_invalid_reduction_strings_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.010s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_invalid_reduction_strings_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.039s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_linear_empty_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.035s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_logsigmoid_out_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_module_to_empty_npu_float64 (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 945, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12399, in test_module_to_empty
    m(input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12390, in forward
    return x @ self.weight
RuntimeError: call aclnnMatmul failed, detail:EZ1001: 2024-09-13-04:03:26.152.308 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:03:26 (PID:1490125, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_module_to_empty_npu_float64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.009s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_module_to_empty_npu_float64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.041s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_nll_loss_all_ignored_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.050s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_nll_loss_byte_target_matches_long_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.048s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_nll_loss_empty_tensor_reduction_mean_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.035s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_nll_loss_empty_tensor_reduction_none_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.047s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_nll_loss_empty_tensor_reduction_sum_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.041s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_nll_loss_out_of_bounds_ignore_index_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.044s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_nll_loss_total_weight_is_zero_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.004s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_nn_empty_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.049s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_nn_scalars_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.088s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_nn_scalars_reductions_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.042s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_nonlinearity_propagate_nan_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_pad_npu_complex128 (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 8827, in test_pad
    inputs = torch.randn(1, 1, 4, device=device, dtype=dtype, requires_grad=True)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py", line 56, in decorated
    return fn(*args, **kwargs)
RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-04:05:26.415.987 self not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:05:26 (PID:1497416, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_pad_npu_complex128

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.009s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_pad_npu_complex128
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'aten::huber_loss' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
.
----------------------------------------------------------------------
Ran 1 test in 0.050s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_smooth_l1_loss_vs_huber_loss_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.036s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_smoothl1loss_backward_zero_beta_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_softplus_low_threshold_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12213, in test_softplus_low_threshold
    output = model(input)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 840, in forward
    return F.softplus(input, self.beta, self.threshold)
RuntimeError: call aclnnSoftplus failed, detail:EZ1001: 2024-09-13-04:05:56.157.741 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:05:56 (PID:1499226, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_softplus_low_threshold_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.007s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_softplus_low_threshold_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.033s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_threshold_inplace_overlap_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_triplet_margin_with_distance_loss_default_parity_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12303, in test_triplet_margin_with_distance_loss_default_parity
    expected = F.triplet_margin_loss(anchor, positive, negative, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4623, in triplet_margin_loss
    return torch.triplet_margin_loss(anchor, positive, negative, margin, p, eps, swap, reduction_enum)
RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-04:06:15.891.591 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:06:15 (PID:1500432, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_triplet_margin_with_distance_loss_default_parity_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.012s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_triplet_margin_with_distance_loss_default_parity_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_triplet_margin_with_distance_loss_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12344, in test_triplet_margin_with_distance_loss
    self.assertTrue(gradcheck(lambda a, p, n: F.triplet_margin_with_distance_loss(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 4130, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2051, in gradcheck
    return _gradcheck_helper(**args)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 2073, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 12344, in <lambda>
    self.assertTrue(gradcheck(lambda a, p, n: F.triplet_margin_with_distance_loss(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4676, in triplet_margin_with_distance_loss
    dist_pos = distance_function(anchor, positive)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/distance.py", line 53, in forward
    return F.pairwise_distance(x1, x2, self.norm, self.eps, self.keepdim)
RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-04:06:25.659.633 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].

[ERROR] 2024-09-13-04:06:25 (PID:1501041, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_triplet_margin_with_distance_loss_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.011s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_triplet_margin_with_distance_loss_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_False_input_size_399_output_size_437_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10070, in test_upsamplingBiLinear2d_consistency_interp_size_bug
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:06:35.669.412 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:06:35 (PID:1501635, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_False_input_size_399_output_size_437_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.046s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_False_input_size_399_output_size_437_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_False_input_size_403_output_size_377_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10070, in test_upsamplingBiLinear2d_consistency_interp_size_bug
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:06:45.339.388 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:06:45 (PID:1502240, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_False_input_size_403_output_size_377_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.046s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_False_input_size_403_output_size_377_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_True_input_size_399_output_size_437_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10070, in test_upsamplingBiLinear2d_consistency_interp_size_bug
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:06:55.503.861 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:06:55 (PID:1502845, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_True_input_size_399_output_size_437_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_True_input_size_399_output_size_437_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_True_input_size_403_output_size_377_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10070, in test_upsamplingBiLinear2d_consistency_interp_size_bug
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:07:05.148.887 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:07:05 (PID:1503450, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_True_input_size_403_output_size_377_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.044s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_True_input_size_403_output_size_377_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9865, in test_upsamplingBiMode2d
    out_t = F.interpolate(in_t, scale_factor=scale_factor, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:07:14.173.936 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:07:14 (PID:1504040, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.011s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9865, in test_upsamplingBiMode2d
    out_t = F.interpolate(in_t, scale_factor=scale_factor, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:07:22.943.708 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:07:22 (PID:1504643, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.011s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:07:32.933.676 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:07:32 (PID:1505243, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.043s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:07:43.494.422 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:07:43 (PID:1505840, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.044s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:07:55.555.827 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:07:55 (PID:1506507, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.044s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:08:05.296.960 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:08:05 (PID:1507122, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.044s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:08:15.003.565 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:08:15 (PID:1507727, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.057s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:08:24.991.238 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:08:24 (PID:1508331, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.057s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:08:34.665.198 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:08:34 (PID:1508922, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.045s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:08:44.723.646 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:08:44 (PID:1509522, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.043s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:08:54.613.111 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:08:54 (PID:1510125, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.044s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:09:04.296.275 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:09:04 (PID:1510728, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.044s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:09:14.184.272 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:09:14 (PID:1511331, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.061s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:09:22.892.565 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:09:22 (PID:1511934, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.058s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:09:32.532.397 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:09:32 (PID:1512534, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.065s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:09:42.486.609 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:09:42 (PID:1513134, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.080s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:09:52.274.193 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:09:52 (PID:1513734, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.070s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:10:02.181.525 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:10:02 (PID:1514334, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.077s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:10:11.694.131 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:10:11 (PID:1514931, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.086s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:10:21.463.794 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:10:21 (PID:1515540, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.100s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:10:30.993.889 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:10:30 (PID:1516149, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.063s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:10:39.770.987 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:10:39 (PID:1516740, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.076s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:10:49.645.666 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:10:49 (PID:1517328, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.067s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:10:59.607.848 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:10:59 (PID:1517931, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.078s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:11:09.591.202 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:11:09 (PID:1518534, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.090s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:11:19.418.199 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:11:19 (PID:1519137, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.102s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:11:32.938.387 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:11:32 (PID:1519740, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.044s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:11:43.695.048 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:11:43 (PID:1520412, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.043s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:11:53.360.053 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:11:53 (PID:1521078, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.041s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:12:03.299.100 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:12:03 (PID:1521678, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.044s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:12:13.163.886 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:12:13 (PID:1522278, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.061s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:12:23.137.470 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:12:23 (PID:1522878, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.060s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:12:32.858.017 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:12:32 (PID:1523523, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.040s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:12:42.603.478 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:12:42 (PID:1524168, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.041s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:12:52.475.825 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:12:52 (PID:1524813, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.043s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:13:02.295.248 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:13:02 (PID:1525458, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.044s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:13:11.902.104 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:13:11 (PID:1526103, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.058s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:13:21.707.457 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:13:21 (PID:1526703, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.060s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:13:31.718.398 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:13:31 (PID:1527312, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.065s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:13:41.460.579 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:13:41 (PID:1527918, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.078s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:13:52.183.909 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:13:52 (PID:1528528, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.067s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:14:01.442.054 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:14:01 (PID:1529137, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.087s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:14:11.077.099 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:14:11 (PID:1529746, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.088s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:14:19.938.060 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:14:19 (PID:1530325, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.101s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:14:29.840.092 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:14:29 (PID:1530928, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.065s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:14:39.367.135 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:14:39 (PID:1531531, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.078s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:14:49.265.749 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:14:49 (PID:1532131, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.067s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:15:01.688.473 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:15:01 (PID:1532731, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.080s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:15:12.124.151 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:15:12 (PID:1533376, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.092s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:15:20.984.695 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:15:20 (PID:1533985, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.104s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:15:30.816.450 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:15:30 (PID:1534579, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.042s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:15:40.559.911 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:15:40 (PID:1535184, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.040s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:15:50.181.141 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:15:50 (PID:1535788, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.041s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:15:58.924.750 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:15:58 (PID:1536376, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.044s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:16:08.789.421 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:16:08 (PID:1536976, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.059s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:16:18.559.419 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:16:18 (PID:1537639, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.059s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:16:28.366.552 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:16:28 (PID:1538239, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.042s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:16:38.206.183 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:16:38 (PID:1538839, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.042s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:16:47.979.963 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:16:47 (PID:1539440, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.042s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:16:57.801.318 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:16:57 (PID:1540040, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.042s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:17:07.654.992 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:17:07 (PID:1540685, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.058s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:17:17.405.880 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:17:17 (PID:1541330, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.060s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:17:27.084.296 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:17:27 (PID:1541974, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.067s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:17:36.865.452 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:17:36 (PID:1542572, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.076s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:17:46.585.864 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:17:46 (PID:1543181, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.065s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:17:56.331.350 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:17:56 (PID:1543790, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.079s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:18:06.263.110 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:18:06 (PID:1544399, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.089s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:18:15.037.919 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:18:15 (PID:1544993, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.100s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:18:28.148.644 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:18:28 (PID:1545583, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.064s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:18:39.673.386 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:18:39 (PID:1546219, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.075s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:18:49.408.808 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:18:49 (PID:1546885, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.064s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:18:59.227.942 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:18:59 (PID:1547485, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.077s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:19:08.997.522 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:19:08 (PID:1548085, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.089s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:19:18.723.495 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:19:18 (PID:1548685, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.101s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:19:28.544.624 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:19:28 (PID:1549330, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.043s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:19:38.349.560 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:19:38 (PID:1549930, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.043s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:19:47.252.285 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:19:47 (PID:1550530, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.044s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:19:56.922.813 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:19:56 (PID:1551131, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:20:06.766.407 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:20:06 (PID:1551731, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.061s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:20:16.478.167 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:20:16 (PID:1552325, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.058s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:20:26.280.453 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:20:26 (PID:1552927, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.041s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:20:34.852.234 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:20:34 (PID:1553517, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.041s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:20:44.764.862 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:20:44 (PID:1554120, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.043s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:20:54.533.648 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:20:54 (PID:1554720, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.042s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:21:04.344.975 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:21:04 (PID:1555320, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.057s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:21:13.143.399 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:21:13 (PID:1555920, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.059s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:21:22.897.706 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:21:22 (PID:1556520, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.063s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:21:32.648.327 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:21:32 (PID:1557117, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.075s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:21:42.407.699 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:21:42 (PID:1557726, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.062s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:21:53.235.105 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:21:53 (PID:1558335, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.077s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:22:05.800.705 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:22:05 (PID:1558935, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.087s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:22:18.171.030 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:22:18 (PID:1559592, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.103s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:22:27.814.231 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:22:27 (PID:1560212, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.062s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:22:37.692.570 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:22:37 (PID:1560821, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.080s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:22:47.569.996 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:22:47 (PID:1561431, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.064s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:22:57.287.255 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:22:57 (PID:1562040, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.076s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:23:06.149.348 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:23:06 (PID:1562619, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.089s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:23:15.773.913 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:23:15 (PID:1563222, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.098s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:23:25.626.436 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:23:25 (PID:1563822, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.045s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:23:35.466.977 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:23:35 (PID:1564422, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:23:45.237.807 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:23:45 (PID:1565022, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:23:54.960.820 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:23:54 (PID:1565622, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:24:04.711.198 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:24:04 (PID:1566222, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.060s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:24:14.297.648 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:24:14 (PID:1566885, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.058s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:24:22.941.139 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:24:22 (PID:1567485, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:24:32.776.282 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:24:32 (PID:1568085, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:24:42.492.077 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:24:42 (PID:1568694, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:24:52.363.766 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:24:52 (PID:1569300, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:25:01.079.602 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:25:01 (PID:1569879, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.060s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:25:11.011.942 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:25:11 (PID:1570482, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.061s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:25:20.767.491 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:25:20 (PID:1571124, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.050s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:25:30.586.559 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:25:30 (PID:1571724, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:25:43.490.696 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:25:43 (PID:1572324, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.053s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:25:55.876.249 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:25:55 (PID:1572997, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:26:05.654.859 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:26:05 (PID:1573663, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.061s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:26:15.408.303 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:26:15 (PID:1574263, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.063s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:26:24.163.476 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:26:24 (PID:1574860, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:26:33.828.293 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:26:33 (PID:1575460, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:26:43.521.425 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:26:43 (PID:1576105, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:26:53.452.509 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:26:53 (PID:1576750, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.050s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:27:01.950.307 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:27:01 (PID:1577341, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.062s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:27:14.965.194 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:27:14 (PID:1577943, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.062s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:27:27.100.644 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:27:27 (PID:1578602, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.051s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:27:39.168.949 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:27:39 (PID:1579241, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:27:50.481.880 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:27:50 (PID:1579874, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.046s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:28:00.128.093 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:28:00 (PID:1580524, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:28:09.926.856 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:28:09 (PID:1581124, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.062s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:28:19.513.475 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:28:19 (PID:1581769, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.060s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:28:29.421.681 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:28:29 (PID:1582414, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:28:38.050.769 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:28:38 (PID:1583005, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:28:47.697.612 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:28:47 (PID:1583608, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:28:57.412.855 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:28:57 (PID:1584213, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:29:06.484.080 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:29:06 (PID:1584800, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.058s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:29:15.192.766 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:29:15 (PID:1585400, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.061s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:29:24.946.136 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:29:24 (PID:1586000, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:29:34.588.752 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:29:34 (PID:1586600, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:29:44.365.547 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:29:44 (PID:1587245, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:29:53.133.370 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:29:53 (PID:1587833, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:30:02.872.182 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:30:02 (PID:1588435, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.061s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:30:12.759.603 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:30:12 (PID:1589040, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.059s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:30:22.310.250 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:30:22 (PID:1589645, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:30:30.977.770 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:30:30 (PID:1590235, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:30:40.831.155 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:30:40 (PID:1590835, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:30:51.046.034 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:30:51 (PID:1591498, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:31:02.255.686 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:31:02 (PID:1592098, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.061s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:31:11.388.620 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:31:11 (PID:1592737, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.064s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:31:20.998.609 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:31:20 (PID:1593337, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:31:30.730.996 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:31:30 (PID:1593937, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:31:40.525.598 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:31:40 (PID:1594534, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.052s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:31:49.269.698 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:31:49 (PID:1595135, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.051s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:31:59.110.838 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:31:59 (PID:1595735, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.063s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:32:08.837.717 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:32:08 (PID:1596335, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.062s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:32:18.602.165 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:32:18 (PID:1596944, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:32:28.343.352 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:32:28 (PID:1597553, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:32:38.253.527 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:32:38 (PID:1598147, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:32:47.869.204 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:32:47 (PID:1598752, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:32:57.546.430 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:32:57 (PID:1599357, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.059s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:33:06.427.390 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:33:06 (PID:1599944, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.060s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:33:16.202.710 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:33:16 (PID:1600544, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:33:25.999.273 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:33:25 (PID:1601144, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:33:35.833.621 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:33:35 (PID:1601744, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:33:45.608.058 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:33:45 (PID:1602344, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:33:55.417.922 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:33:55 (PID:1602944, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.061s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:34:04.227.765 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:34:04 (PID:1603589, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.060s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:34:17.045.912 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:34:17 (PID:1604189, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:34:27.419.143 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:34:27 (PID:1604831, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:34:36.174.916 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:34:36 (PID:1605434, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:34:46.023.112 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:34:46 (PID:1606031, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:34:55.864.236 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:34:55 (PID:1606632, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.061s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:35:05.638.822 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:35:05 (PID:1607232, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.059s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:35:15.466.076 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:35:15 (PID:1607832, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:35:25.172.104 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:35:25 (PID:1608432, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:35:34.909.421 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:35:34 (PID:1609032, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.047s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:35:44.638.567 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:35:44 (PID:1609677, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.050s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:35:54.638.008 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:35:54 (PID:1610322, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.062s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:36:04.597.444 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:36:04 (PID:1610967, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.061s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:36:13.364.290 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:36:13 (PID:1611567, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:36:23.070.859 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:36:23 (PID:1612161, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:36:32.876.387 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:36:32 (PID:1612763, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:36:42.607.818 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:36:42 (PID:1613368, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:36:51.387.708 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:36:51 (PID:1613958, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.062s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:37:01.232.638 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:37:01 (PID:1614558, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.059s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:37:10.998.124 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:37:10 (PID:1615158, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:37:20.786.477 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:37:20 (PID:1615758, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:37:30.362.846 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:37:30 (PID:1616424, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.049s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:37:39.285.602 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:37:39 (PID:1617023, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:37:49.823.077 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:37:49 (PID:1617622, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.060s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:38:02.296.379 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:38:02 (PID:1618270, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.061s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:38:12.037.292 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:38:12 (PID:1618918, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:38:23.690.840 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:38:23 (PID:1619622, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.051s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:38:33.724.357 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:38:33 (PID:1620883, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.051s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:38:43.566.718 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:38:43 (PID:1621492, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.048s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:38:52.125.986 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:38:52 (PID:1622080, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.062s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 10004, in test_upsamplingBiMode2d_consistency
    output_ui8 = F.interpolate(
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4020, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-04:39:01.820.938 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:39:01 (PID:1622664, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.065s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bicubic_float64_npu_float64 (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9941, in test_upsamplingBiMode2d_nonsupported_dtypes
    _ = F.interpolate(x, (12, 12), mode=mode, antialias=antialias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:39:11.685.899 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:39:11 (PID:1623261, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bicubic_float64_npu_float64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.011s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bicubic_float64_npu_float64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bicubic_float64_npu_float64 (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1120, in only_fn
    return fn(self, *args, **kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9941, in test_upsamplingBiMode2d_nonsupported_dtypes
    _ = F.interpolate(x, (12, 12), mode=mode, antialias=antialias)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 4028, in interpolate
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-04:39:21.385.767 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].

[ERROR] 2024-09-13-04:39:21 (PID:1623855, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bicubic_float64_npu_float64

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.011s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bicubic_float64_npu_float64
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
.
----------------------------------------------------------------------
Ran 1 test in 0.040s

OK
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingBicubic2d_correctness_npu
/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:211: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
ditorch.framework: torch_npu:2.1.0.post3
E
======================================================================
ERROR: test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest_npu (test_nn.TestNNDeviceTypePRIVATEUSE1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2387, in wrapper
    method(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 428, in instantiated_test
    raise rte
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 415, in instantiated_test
    result = test(self, **param_kwargs)
  File "/deeplink_afs/zhangqiu/pytorch_test/general_device_test/custome_tools/test_nn.py", line 9761, in test_upsamplingNearest3d
    out_uint8_t = m(in_uint8_t)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/modules/upsampling.py", line 156, in forward
    return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners,
  File "/opt/miniconda3/envs/torch_npu_py39/lib/python3.9/site-packages/torch/nn/functional.py", line 3985, in interpolate
    return torch._C._nn.upsample_nearest3d(input, output_size, scale_factors)
RuntimeError: call aclnnUpsampleNearest3d failed, detail:EZ1001: 2024-09-13-04:39:40.890.112 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_DOUBLE,].

[ERROR] 2024-09-13-04:39:40 (PID:1625043, Device:0, RankID:-1) ERR01005 OPS internal error

To execute this test, run the following from the base repo dir:
     python test_nn.py -k test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest_npu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

----------------------------------------------------------------------
Ran 1 test in 0.037s

FAILED (errors=1)
Class: TestNNDeviceTypePRIVATEUSE1, Method: test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest_npu
