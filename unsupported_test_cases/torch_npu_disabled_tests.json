{
    "test_AdaptiveLogSoftmax_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_BCELoss_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-11-07:18:12.649.486 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_BCELoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-11-07:18:12.677.664 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_BCELoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-11-07:18:12.702.496 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_BCELoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-11-07:18:12.713.764 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_BCELoss_no_reduce_scalar_cuda (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_BCELoss_scalar_weights_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-11-07:18:13.141.646 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_BCELoss_weights_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-11-07:18:13.350.497 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_BCEWithLogitsLoss_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-11-07:18:14.537.880 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_BCEWithLogitsLoss_cuda_float (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_BCEWithLogitsLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-11-07:18:17.044.059 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_BCEWithLogitsLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-11-07:18:17.062.184 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_BCEWithLogitsLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-11-07:18:17.070.935 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_BCEWithLogitsLoss_scalar_weights_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-11-07:18:18.154.364 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_BCEWithLogitsLoss_scalar_weights_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_BCEWithLogitsLoss_scalar_weights_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_BCEWithLogitsLoss_weights_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-11-07:18:19.037.708 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_2d_int_target_lengths_intlists_cuda_double (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_2d_int_target_lengths_intlists_cuda_float (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_2d_int_target_lengths_intlists_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_2d_int_target_lengths_intlists_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_2d_int_target_lengths_tensors_cuda_double (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_2d_int_target_lengths_tensors_cuda_float (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_2d_int_target_lengths_tensors_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_2d_int_target_lengths_tensors_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_2d_lengths_tensors_cuda_double (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_2d_lengths_tensors_cuda_float (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_2d_lengths_tensors_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_2d_lengths_tensors_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_critical_target_len (__main__.TestNN)": [
        "RuntimeError: only npu tensor is supported",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_lengths_intlists_cuda_double (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_lengths_intlists_cuda_float (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_lengths_intlists_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_lengths_intlists_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_lengths_tensors_cuda_double (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_lengths_tensors_cuda_float (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_lengths_tensors_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_lengths_tensors_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_circular_stride2_pad2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_dilated_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_groups_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_pad1_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_pad1size1_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_pad2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_pad2size1_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_pad_same2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_pad_same_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_pad_same_dilated_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_pad_valid_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_reflect_stride2_pad2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_replicate_stride2_pad2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_stride_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv1d_zeros_stride2_pad2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_circular_stride2_pad2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_depthwise_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_depthwise_dilated_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_depthwise_padded_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_depthwise_strided_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_depthwise_with_multiplier_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_dilated_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_groups_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_groups_thnn_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_no_bias_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_pad_same_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_pad_same_dilated_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_pad_valid_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_padding_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_reflect_stride2_pad2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_replicate_stride2_pad2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_strided_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv2d_zeros_stride2_pad2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d (__main__.TestNN)": [
        "RuntimeError: The Inner error is reported as above.",
        [
            "linux"
        ]
    ],
    "test_Conv3d_1x1x1_no_bias_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_circular_stride2_pad2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_dilated_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_dilated_strided_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_groups_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_no_bias_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_pad_same_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_pad_same_dilated_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_pad_valid_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_replicate_stride2_pad2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_stride_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_stride_padding_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_zero_batch_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Conv3d_zeros_stride2_pad2_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ConvTranspose1d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ConvTranspose1d_dilated_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ConvTranspose1d_groups_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ConvTranspose1d_no_bias_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ConvTranspose2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ConvTranspose2d_dilated_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ConvTranspose2d_groups_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ConvTranspose2d_no_bias_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ConvTranspose3d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ConvTranspose3d_dilated_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_margin_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_margin_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_margin_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_margin_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_margin_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_margin_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CosineEmbeddingLoss_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:45.597.606 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_ignore_index_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:45.614.726 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_ignore_index_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_ignore_index_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_indices_target_smoothing_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:45.631.285 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_indices_target_smoothing_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_indices_target_smoothing_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_indices_target_smoothing_ignore_index_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:45.651.676 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_indices_target_smoothing_ignore_index_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_indices_target_smoothing_ignore_index_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_indices_target_smoothing_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:45.669.637 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_indices_target_smoothing_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_indices_target_smoothing_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_indices_target_smoothing_weight_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:45.687.777 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_indices_target_smoothing_weight_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_indices_target_smoothing_weight_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_smoothing_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_smoothing_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_smoothing_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_smoothing_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_smoothing_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_smoothing_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_smoothing_weight_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_smoothing_weight_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_smoothing_weight_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_weights_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_weights_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_weights_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_weights_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_weights_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_prob_target_weights_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:45.747.404 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_weights_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:45.762.802 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_weights_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_2d_weights_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_indices_target_smoothing_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:45.782.123 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_indices_target_smoothing_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_indices_target_smoothing_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_indices_target_smoothing_ignore_index_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:45.800.553 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_indices_target_smoothing_ignore_index_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_indices_target_smoothing_ignore_index_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:45.818.018 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_ignore_index_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:45.837.069 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_ignore_index_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_ignore_index_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_smoothing_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_smoothing_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_smoothing_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_smoothing_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_smoothing_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_smoothing_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_weights_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_weights_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_weights_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_weights_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_weights_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_3d_prob_target_weights_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_4d_prob_target_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_4d_prob_target_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_4d_prob_target_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_4d_prob_target_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_4d_prob_target_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_4d_prob_target_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_4d_prob_target_weights_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_4d_prob_target_weights_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_4d_prob_target_weights_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_4d_prob_target_weights_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_4d_prob_target_weights_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_4d_prob_target_weights_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:45.914.210 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_dim_is_3_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:45.930.781 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_dim_is_3_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_dim_is_3_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_dim_is_3_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:45.946.849 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_dim_is_3_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_dim_is_3_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_higher_dim_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:45.963.172 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_higher_dim_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_higher_dim_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_higher_dim_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:45.979.691 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_higher_dim_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_higher_dim_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_weights_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:45.994.720 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_weights_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossEntropyLoss_weights_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_CrossMapLRN2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ELU_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_EmbeddingBag_discontiguous_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_EmbeddingBag_max_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_EmbeddingBag_max_padding_idx_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_EmbeddingBag_mean_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_EmbeddingBag_mean_padding_idx_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_EmbeddingBag_sparse_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_EmbeddingBag_sum_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_EmbeddingBag_sum_padding_idx_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Embedding_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Embedding_discontiguous_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Embedding_sparse_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Flatten_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Flatten_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Fold_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Fold_int_input_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Fold_no_batch_dim_input_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Fold_no_batch_dim_int_input_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_GELU_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_GLU_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Hardshrink_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Hardsigmoid_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Hardswish_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Hardtanh_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_margin_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_margin_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_margin_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_margin_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_margin_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_margin_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_margin_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_scalar_margin_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_scalar_margin_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_scalar_margin_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_scalar_margin_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_scalar_margin_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_scalar_margin_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HingeEmbeddingLoss_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_HuberLoss_delta (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_HuberLoss_delta_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:18:46.543.979 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_log_target_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:18:47.037.479 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_log_target_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_log_target_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_log_target_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:18:48.037.471 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_log_target_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_log_target_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:18:48.447.186 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:18:48.456.921 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:18:48.465.337 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_reduce (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_reduce_log_target (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_reduce_log_target_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_reduce_scalar (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_reduce_scalar_cuda (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_reduce_scalar_log_target (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_no_reduce_scalar_log_target_cuda (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_scalar_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:18:49.247.715 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_scalar_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_scalar_log_target_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:18:49.256.326 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_scalar_log_target_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_scalar_log_target_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:18:49.264.461 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_scalar_log_target_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_scalar_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:18:49.272.340 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_scalar_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:18:49.445.660 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_with_log_target_no_reduce (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_with_log_target_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_with_target_no_reduce (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_KLDivLoss_with_target_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_L1Loss_cuda_cdouble (__main__.TestNN)": [
        "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-11-07:18:50.749.348 Input dtype should be either floating point or complex dtypes. Got self DT_COMPLEX128 and target DT_COMPLEX128 instead.",
        [
            "linux"
        ]
    ],
    "test_L1Loss_cuda_cfloat (__main__.TestNN)": [
        "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-11-07:18:50.753.781 Input dtype should be either floating point or complex dtypes. Got self DT_COMPLEX64 and target DT_COMPLEX64 instead.",
        [
            "linux"
        ]
    ],
    "test_L1Loss_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-11-07:18:50.757.348 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_L1Loss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_L1Loss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-11-07:18:50.766.767 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-11-07:18:50.775.772 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-11-07:18:50.783.813 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_reduce (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_reduce_complex (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_reduce_complex_cuda (__main__.TestNN)": [
        "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-11-07:18:50.797.051 promoteType dtype DT_COMPLEX128 should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_reduce_scalar (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_L1Loss_no_reduce_scalar_cuda (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_L1Loss_scalar_cuda_cdouble (__main__.TestNN)": [
        "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-11-07:18:50.808.523 Input dtype should be either floating point or complex dtypes. Got self DT_COMPLEX128 and target DT_COMPLEX128 instead.",
        [
            "linux"
        ]
    ],
    "test_L1Loss_scalar_cuda_cfloat (__main__.TestNN)": [
        "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-11-07:18:50.812.060 Input dtype should be either floating point or complex dtypes. Got self DT_COMPLEX64 and target DT_COMPLEX64 instead.",
        [
            "linux"
        ]
    ],
    "test_L1Loss_scalar_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-11-07:18:50.815.494 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_L1Loss_scalar_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_L1Loss_scalar_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_LayerNorm_3d_no_affine_large_feature_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_LayerNorm_3d_no_affine_large_feature_eval_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_LeakyReLU_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Linear_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Linear_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Linear_no_bias_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_LogSigmoid_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-11-07:18:51.312.627 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
        [
            "linux"
        ]
    ],
    "test_MSELoss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-11-07:18:51.323.240 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-11-07:18:51.332.994 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-11-07:18:51.342.116 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_reduce (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_reduce_scalar (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_MSELoss_no_reduce_scalar_cuda (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_prec_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_prec_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-11-07:18:51.405.130 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
        [
            "linux"
        ]
    ],
    "test_MSELoss_prec_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_prec_cuda_half (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_scalar_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_scalar_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-11-07:18:51.451.253 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
        [
            "linux"
        ]
    ],
    "test_MSELoss_scalar_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_scalar_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_scalar_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_scalar_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-11-07:18:51.463.570 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
        [
            "linux"
        ]
    ],
    "test_MSELoss_scalar_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_scalar_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-11-07:18:51.473.869 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
        [
            "linux"
        ]
    ],
    "test_MSELoss_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MSELoss_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_margin_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_margin_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_margin_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_margin_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_margin_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_margin_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_sum_reduction_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MarginRankingLoss_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MaxUnpool1d_net (__main__.TestNN)": [
        "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-11-07:18:51.544.571 indices expected scalar type DT_INT64 but found DT_INT8.",
        [
            "linux"
        ]
    ],
    "test_MaxUnpool1d_net_cuda (__main__.TestNN)": [
        "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-11-07:18:51.550.243 indices expected scalar type DT_INT64 but found DT_INT8.",
        [
            "linux"
        ]
    ],
    "test_MaxUnpool1d_net_no_batch_dim (__main__.TestNN)": [
        "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-11-07:18:51.560.880 indices expected scalar type DT_INT64 but found DT_INT8.",
        [
            "linux"
        ]
    ],
    "test_MaxUnpool1d_net_no_batch_dim_cuda (__main__.TestNN)": [
        "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-11-07:18:51.566.575 indices expected scalar type DT_INT64 but found DT_INT8.",
        [
            "linux"
        ]
    ],
    "test_MaxUnpool2d_net (__main__.TestNN)": [
        "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-11-07:18:51.575.871 indices expected scalar type DT_INT64 but found DT_INT8.",
        [
            "linux"
        ]
    ],
    "test_MaxUnpool2d_net_cuda (__main__.TestNN)": [
        "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-11-07:18:51.580.901 indices expected scalar type DT_INT64 but found DT_INT8.",
        [
            "linux"
        ]
    ],
    "test_MaxUnpool2d_net_no_batch_dim (__main__.TestNN)": [
        "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-11-07:18:51.590.565 indices expected scalar type DT_INT64 but found DT_INT8.",
        [
            "linux"
        ]
    ],
    "test_MaxUnpool2d_net_no_batch_dim_cuda (__main__.TestNN)": [
        "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-11-07:18:51.595.892 indices expected scalar type DT_INT64 but found DT_INT8.",
        [
            "linux"
        ]
    ],
    "test_MaxUnpool3d_net_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_MaxUnpool3d_net_no_batch_dim (__main__.TestNN)": [
        "RuntimeError: call aclnnMaxUnpool3d failed, detail:EZ1001: 2024-09-11-07:18:51.610.266 indices expected scalar type DT_INT64 but found DT_FLOAT.",
        [
            "linux"
        ]
    ],
    "test_MaxUnpool3d_net_no_batch_dim_cuda (__main__.TestNN)": [
        "RuntimeError: call aclnnMaxUnpool3d failed, detail:EZ1001: 2024-09-11-07:18:51.615.934 indices expected scalar type DT_INT64 but found DT_FLOAT.",
        [
            "linux"
        ]
    ],
    "test_Mish_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_1d_cuda_bfloat16 (__main__.TestNN)": [
        "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-11-07:18:51.650.098 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_1d_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-11-07:18:51.655.966 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_1d_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_1d_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_1d_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_1d_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
        "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-11-07:18:51.671.993 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_1d_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-11-07:18:51.677.793 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_1d_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_1d_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_cuda_bfloat16 (__main__.TestNN)": [
        "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-11-07:18:51.685.761 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-11-07:18:51.691.550 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_index_neg_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-11-07:18:51.705.317 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-11-07:18:51.714.879 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-11-07:18:51.723.831 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
        "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-11-07:18:51.775.393 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-11-07:18:51.781.507 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelMarginLoss_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-11-07:18:51.792.256 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-11-07:18:51.804.249 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-11-07:18:51.815.995 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-11-07:18:51.827.421 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_weights_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-11-07:18:51.842.920 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_weights_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_weights_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_weights_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_weights_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-11-07:18:51.858.829 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_weights_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiLabelSoftMarginLoss_weights_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_1d_cuda_half (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_1d_no_reduce (__main__.TestNN)": [
        "RuntimeError: target out of range",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_1d_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_1d_sum_reduction_cuda_half (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_cuda_half (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_margin_cuda_half (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_margin_no_reduce (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_margin_no_reduce_cuda (__main__.TestNN)": [
        "RuntimeError: target out of range",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_margin_sum_reduction_cuda_half (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_no_reduce (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_no_reduce_cuda (__main__.TestNN)": [
        "RuntimeError: target out of range",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_p_cuda_half (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_p_no_reduce (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_p_no_reduce_cuda (__main__.TestNN)": [
        "RuntimeError: target out of range",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_p_sum_reduction_cuda_half (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_sum_reduction_cuda_half (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_weights_cuda_half (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_weights_no_reduce (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_weights_no_reduce_cuda (__main__.TestNN)": [
        "RuntimeError: target out of range",
        [
            "linux"
        ]
    ],
    "test_MultiMarginLoss_weights_sum_reduction_cuda_half (__main__.TestNN)": [
        "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
        [
            "linux"
        ]
    ],
    "test_NLLLoss2d_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss2d_no_reduce_ignore_index_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss2d_no_reduce_weights_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLossNd_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLossNd_no_reduce_ignore_index_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLossNd_no_reduce_weights_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:53.447.402 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_ignore_index_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_ignore_index_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:53.463.385 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_ignore_index_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_ignore_index_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:53.479.103 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_weights_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_weights_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:53.493.837 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_weights_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_2d_weights_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:53.504.871 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_dim_is_3_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_dim_is_3_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:53.519.023 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_dim_is_3_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_dim_is_3_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_dim_is_3_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_dim_is_3_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:53.533.525 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_dim_is_3_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_dim_is_3_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_higher_dim_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_higher_dim_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:53.554.458 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_higher_dim_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_higher_dim_cuda_half (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_higher_dim_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_higher_dim_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-11-07:18:53.575.534 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_higher_dim_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_higher_dim_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_ignore_index_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_ignore_index_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:53.739.237 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_ignore_index_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_ignore_index_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:53.752.857 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:53.765.679 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:53.778.007 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_reduce_ignore_index_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_reduce_weights_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_reduce_weights_ignore_index_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_no_reduce_weights_ignore_index_neg_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:54.651.831 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_weights_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_weights_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:54.847.970 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_weights_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_weights_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_weights_ignore_index_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_weights_ignore_index_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:55.046.425 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_weights_ignore_index_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_weights_ignore_index_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_weights_ignore_index_neg_cuda_bfloat16 (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_weights_ignore_index_neg_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:18:55.249.138 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_weights_ignore_index_neg_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_NLLLoss_weights_ignore_index_neg_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PReLU_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_PairwiseDistance_broadcast_lhs_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_PairwiseDistance_broadcast_rhs_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_PairwiseDistance_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_PairwiseDistance_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PairwiseDistance_with_non_default_args_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_PixelShuffle_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_PixelUnshuffle_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_full_loss_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnInplaceMaskedFillScalar failed, detail:EZ1001: 2024-09-11-07:18:56.242.529 selfRef not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_full_loss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_full_loss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_full_loss_no_log_input_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnInplaceMaskedFillScalar failed, detail:EZ1001: 2024-09-11-07:18:58.144.551 selfRef not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_full_loss_no_log_input_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_full_loss_no_log_input_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_full_loss_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_full_loss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_full_loss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_full_loss_no_log_input_cuda_double (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_full_loss_no_log_input_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_full_loss_no_log_input_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_PoissonNLLLoss_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_RNN_change_dropout (__main__.TestNN)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:19:02.293.232 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_RNN_cpu_vs_cudnn_no_dropout (__main__.TestNN)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:19:02.350.607 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_RNN_cpu_vs_cudnn_with_dropout (__main__.TestNN)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:19:02.364.129 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_RNN_cudnn_weight_norm (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_RNN_dropout (__main__.TestNN)": [
        "RuntimeError: call aclnnMatmul failed, detail:EZ1001: 2024-09-11-07:19:02.972.636 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_RNN_dropout_state (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ReLU6_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ReLU_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad3d_complex (__main__.TestNN)": [
        "RuntimeError: npu_dtype_cast does not support automatic differentiation for outputs with complex dtype.",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad3d_complex_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad3d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad3d_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_SELU_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_SiLU_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Sigmoid_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_beta (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_beta_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-11-07:19:03.104.234 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-11-07:19:03.114.862 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-11-07:19:03.124.636 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-11-07:19:03.148.853 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_reduce (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_reduce_scalar (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_no_reduce_scalar_cuda (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_scalar_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-11-07:19:03.168.336 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_scalar_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_scalar_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_scalar_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-11-07:19:03.180.652 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_scalar_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_scalar_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-11-07:19:03.192.329 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_zero_beta (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_SmoothL1Loss_zero_beta_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-11-07:19:03.207.117 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-11-07:19:03.217.795 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-11-07:19:03.222.602 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
        "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-11-07:19:03.227.262 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-11-07:19:03.234.095 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-11-07:19:03.238.796 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
        "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-11-07:19:03.243.692 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-11-07:19:03.252.390 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
        "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-11-07:19:03.257.595 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
        "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-11-07:19:03.262.619 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_no_reduce (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_sum_reduction_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-11-07:19:03.274.490 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_sum_reduction_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_SoftMarginLoss_sum_reduction_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_Softplus_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Softshrink_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Softsign_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Tanh_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Tanhshrink_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Threshold_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_TransformerDecoderLayer_gelu_activation_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_TransformerDecoderLayer_relu_activation (__main__.TestNN)": [
        "OverTimeError: Test exceeded time limit of 60 seconds.",
        [
            "linux"
        ]
    ],
    "test_TransformerDecoderLayer_relu_activation_cuda (__main__.TestNN)": [
        "OverTimeError: Test exceeded time limit of 60 seconds.",
        [
            "linux"
        ]
    ],
    "test_TransformerEncoderLayer_gelu_activation_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_TransformerEncoderLayer_relu_activation_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Transformer_multilayer_coder_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_TripletMarginLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-11-07:21:04.451.292 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_TripletMarginLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_TripletMarginLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_TripletMarginLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-11-07:21:04.473.841 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_TripletMarginLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_TripletMarginLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_TripletMarginLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
        "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-11-07:21:04.490.806 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_TripletMarginLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_TripletMarginLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_Unflatten_no_batch_dim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Unfold_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_Unfold_int_input_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_affine_grid (__main__.TestNN)": [
        "RuntimeError: call aclnnAffineGrid failed, detail:EZ1001: 2024-09-11-07:21:04.528.828 theta not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_affine_grid_3d (__main__.TestNN)": [
        "RuntimeError: call aclnnAffineGrid failed, detail:EZ1001: 2024-09-11-07:21:04.535.633 theta not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_batchnorm_cudnn_nhwc (__main__.TestNN)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_batchnorm_nhwc_cpu (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_nhwc_cuda (__main__.TestNN)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_batchnorm_non_contig_cpu_SyncBatchNorm (__main__.TestNN)": [
        "ValueError: SyncBatchNorm expected input tensor to be on NPU or GPU",
        [
            "linux"
        ]
    ],
    "test_batchnorm_raises_error_if_running_var_or_running_mean_have_forward_grad (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_bce_with_logits_has_correct_forward_grad (__main__.TestNN)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_convert_sync_batchnorm (__main__.TestNN)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_cosine_embedding_loss_with_diff_type (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cudnn_weight_format (__main__.TestNN)": [
        "AssertionError: Scalars are not equal!",
        [
            "linux"
        ]
    ],
    "test_cudnn_weight_tying (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_error_RNN_seq_len_zero (__main__.TestNN)": [
        "IndexError: select(): index -1 out of range for tensor of size [0, 10, 6] at dimension 0",
        [
            "linux"
        ]
    ],
    "test_grid_sample (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_grid_sample_3d (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_grid_sample_error_checking (__main__.TestNN)": [
        "AssertionError: \"Expected all tensors to be on the same device\" does not match \"only npu tensor is supported",
        [
            "linux"
        ]
    ],
    "test_grid_sample_nearest_neighbor_rounding_mode_consistency (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not equal!",
        [
            "linux"
        ]
    ],
    "test_interpolate (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bicubic_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bicubic_2d_zero_dim_cuda (__main__.TestNN)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_interpolate_bicubic_scale_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bicubic_scale_tuple_shared_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bicubic_scale_tuple_skewed_2d_align_corners_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bicubic_scale_tuple_skewed_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bicubic_tuple_2d_align_corners_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bicubic_tuple_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bilinear_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bilinear_2d_zero_dim_cuda (__main__.TestNN)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_interpolate_bilinear_scale_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bilinear_scale_tuple_shared_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bilinear_scale_tuple_skewed_2d_align_corners_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bilinear_scale_tuple_skewed_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bilinear_tuple_2d_align_corners_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_bilinear_tuple_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_illegal_memory_access (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_linear_1d_align_corners_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_linear_1d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_linear_1d_zero_dim_cuda (__main__.TestNN)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_interpolate_linear_scale_1d_align_corners_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_linear_scale_1d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_linear_tuple_1d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_1d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_1d_zero_dim_cuda (__main__.TestNN)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_2d_launch_configs_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_2d_zero_dim_cuda (__main__.TestNN)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_3d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_3d_zero_dim_cuda (__main__.TestNN)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_scale_1d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_scale_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_scale_3d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_tuple_1d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_tuple_2d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_nearest_tuple_3d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_trilinear_3d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_trilinear_3d_zero_dim_cuda (__main__.TestNN)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_interpolate_trilinear_scale_3d_align_corners_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_trilinear_scale_3d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_trilinear_tuple_3d_align_corners_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_interpolate_trilinear_tuple_3d_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_kl_div_log_softmax_target (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:21:12.709.737 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_kl_div_with_diff_type (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:21:12.714.133 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_kl_div_with_diff_type_log_target (__main__.TestNN)": [
        "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-11-07:21:12.718.284 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_layer_norm_grads_with_create_graph_flag (__main__.TestNN)": [
        "RuntimeError: call aclnnLayerNorm failed, detail:EZ1001: 2024-09-11-07:21:21.730.823 input not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_linear_autograd_device_cuda_bias_weightCOO (__main__.TestNN)": [
        "RuntimeError: CAUTION: The operator 'aten::addmm' is not currently supported on the NPU backend.",
        [
            "linux"
        ]
    ],
    "test_linear_autograd_device_cuda_bias_weightCSC (__main__.TestNN)": [
        "RuntimeError: device type of values (npu) must be CPU or CUDA",
        [
            "linux"
        ]
    ],
    "test_linear_autograd_device_cuda_bias_weightCSR (__main__.TestNN)": [
        "RuntimeError: device type of values (npu) must be CPU or CUDA",
        [
            "linux"
        ]
    ],
    "test_linear_autograd_device_cuda_bias_weightStrided (__main__.TestNN)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:21:21.799.539 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_linear_autograd_device_cuda_nobias_weightCOO (__main__.TestNN)": [
        "RuntimeError: CAUTION: The operator 'aten::addmm' is not currently supported on the NPU backend.",
        [
            "linux"
        ]
    ],
    "test_linear_autograd_device_cuda_nobias_weightCSC (__main__.TestNN)": [
        "RuntimeError: device type of values (npu) must be CPU or CUDA",
        [
            "linux"
        ]
    ],
    "test_linear_autograd_device_cuda_nobias_weightCSR (__main__.TestNN)": [
        "RuntimeError: device type of values (npu) must be CPU or CUDA",
        [
            "linux"
        ]
    ],
    "test_linear_autograd_device_cuda_nobias_weightStrided (__main__.TestNN)": [
        "RuntimeError: call aclnnMatmul failed, detail:EZ1001: 2024-09-11-07:21:21.848.592 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_load_state_dict_ref_cycle (__main__.TestNN)": [
        "AssertionError: Scalars are not equal!",
        [
            "linux"
        ]
    ],
    "test_log_softmax_dim0_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_log_softmax_dim3_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_log_softmax_lastdim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_log_softmax_scalar_cuda (__main__.TestNN)": [
        "RuntimeError: call aclnnLogSoftmaxBackward failed, detail:EZ1001: 2024-09-11-07:21:22.349.486 provided dim 0 not in the range of input size 0.",
        [
            "linux"
        ]
    ],
    "test_log_softmax_spatial_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_log_softmax_spatial_special_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_multimarginloss_1d_input_0d_target_no_reduce (__main__.TestNN)": [
        "RuntimeError: target out of range",
        [
            "linux"
        ]
    ],
    "test_multimarginloss_1d_input_0d_target_no_reduce_cuda (__main__.TestNN)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_partial_flat_weights (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_pdist (__main__.TestNN)": [
        "RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-11-07:21:22.999.465 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_pdist_empty_col (__main__.TestNN)": [
        "RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-11-07:21:23.020.447 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_pdist_empty_row (__main__.TestNN)": [
        "RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-11-07:21:23.027.547 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_pdist_large (__main__.TestNN)": [
        "RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-11-07:21:23.050.839 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_pdist_zeros (__main__.TestNN)": [
        "RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-11-07:21:23.059.435 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_smoothl1loss_intergral_target (__main__.TestNN)": [
        "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-11-07:21:30.248.154 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_softmax_lastdim_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_softmax_spatial_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_softmax_spatial_special_cuda (__main__.TestNN)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_sync_batchnorm_accuracy_cuda (__main__.TestNN)": [
        "RuntimeError: NPU not support specify memory_format.",
        [
            "linux"
        ]
    ],
    "test_sync_batchnorm_backward_elemt (__main__.TestNN)": [
        "RuntimeError: call aclnnBatchNormElemtBackward failed, detail:EZ1001: 2024-09-11-07:21:30.335.393 gradOut not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_transformerdecoder (__main__.TestNN)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:21:30.472.216 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_type (__main__.TestNN)": [
        "AssertionError: tensor([[-0., -0., -0., -0., 0., -0., 0., -0., -0., 0.],",
        [
            "linux"
        ]
    ],
    "test_upsampling_not_recompute_scale_factor (__main__.TestNN)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:21:40.519.353 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_fold_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bilinear_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bilinear_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bilinear_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bilinear_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bicubic_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bilinear_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bilinear_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bicubic_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bilinear_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bilinear_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest1d_mode_nearest-exact_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest1d_mode_nearest_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_memory_format_torch_channels_last_mode_nearest-exact_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_memory_format_torch_channels_last_mode_nearest_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_memory_format_torch_contiguous_format_mode_nearest-exact_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_memory_format_torch_contiguous_format_mode_nearest_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_memory_format_torch_channels_last_3d_mode_nearest-exact_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_memory_format_torch_channels_last_3d_mode_nearest_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest-exact_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest_cpu (__main__.TestNNDeviceTypeCPU)": [
        "AttributeError: 'function' object has no attribute 'graph'",
        [
            "linux"
        ]
    ],
    "test_BatchNorm_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_Bilinear_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_cudnn_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: only npu tensor is supported",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_empty_target_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: False is not true",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: only npu tensor is supported",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: only npu tensor is supported",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_no_batch_dim_reduction_none_use_module_form_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: only npu tensor is supported",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_no_batch_dim_reduction_none_use_module_form_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: only npu tensor is supported",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: only npu tensor is supported",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: only npu tensor is supported",
        [
            "linux"
        ]
    ],
    "test_GRU_grad_and_gradgrad_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-11-07:23:44.866.593 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_GroupNorm_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnGroupNorm failed, detail:EZ1001: 2024-09-11-07:23:44.872.255 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_BFLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_GroupNorm_general_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnGroupNorm failed, detail:EZ1001: 2024-09-11-07:23:44.880.834 Expected eps to be greater than 0, got 0.000000.",
        [
            "linux"
        ]
    ],
    "test_GroupNorm_memory_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU not support specify memory_format.",
        [
            "linux"
        ]
    ],
    "test_GroupNorm_numeric_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_InstanceNorm1d_general_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_InstanceNorm2d_general_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_InstanceNorm3d_general_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_LSTM_grad_and_gradgrad_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-11-07:23:44.910.304 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_LayerNorm_general_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_LayerNorm_numeric_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_LocalResponseNorm_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_MarginLoss_empty_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_MarginLoss_empty_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_MarginLoss_warnings_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:23:44.970.504 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_ReflectionPad2d_large_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ReflectionPad3d_large_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_ReflectionPad_empty_cuda_complex64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-11-07:23:45.628.917 self not implemented for DT_COMPLEX64, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_ReflectionPad_empty_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad1d_large_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad2d_large_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad3d_large_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad_empty_cuda_complex128 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-11-07:23:46.003.723 self not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad_empty_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_TransformerDecoderLayer_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:23:46.040.346 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_TransformerDecoder_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:23:46.078.876 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_TransformerEncoderLayer_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:23:46.103.945 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_TransformerEncoder_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:23:46.133.035 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_Transformer_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:23:46.634.057 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_Unfold_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnIm2col failed, detail:EZ1001: 2024-09-11-07:23:46.642.949 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_activations_bfloat16_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_affine_2d_rotate0_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_affine_2d_rotate45_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_affine_2d_rotate90_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_affine_2d_rotateRandom_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_affine_3d_rotateRandom_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_affine_cuda_bfloat16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_affine_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_affine_mixed_cuda_bfloat16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_affine_mixed_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_eval_cuda_bfloat16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_eval_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_eval_mixed_cuda_bfloat16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_eval_mixed_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_grad_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnBatchNorm failed, detail:EZ1001: 2024-09-11-07:23:46.688.095 input not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_batchnorm_simple_average_cuda_bfloat16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_simple_average_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_simple_average_mixed_cuda_bfloat16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_simple_average_mixed_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_update_stats_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not equal!",
        [
            "linux"
        ]
    ],
    "test_channel_shuffle_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not equal!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_error_if_nonfinite_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-11-07:23:46.709.804 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_False_norm_type_0_5_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_False_norm_type_1_5_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_False_norm_type_2_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-11-07:23:46.724.017 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_False_norm_type_4_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_False_norm_type_inf_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_True_norm_type_0_5_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_True_norm_type_1_5_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_True_norm_type_2_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-11-07:23:46.737.891 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_True_norm_type_4_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_True_norm_type_inf_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_value_foreach_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: tensor(0., device='npu:0') not less than or equal to 2.5",
        [
            "linux"
        ]
    ],
    "test_clip_grad_value_foreach_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: tensor(0., device='npu:0') not less than or equal to 2.5",
        [
            "linux"
        ]
    ],
    "test_conv_empty_input_cuda_complex128 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnAdd failed, detail:EZ1001: 2024-09-11-07:23:46.818.880 other not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT16,DT_INT8,DT_UINT8,DT_DOUBLE,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_conv_empty_input_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU not support specify memory_format.",
        [
            "linux"
        ]
    ],
    "test_conv_empty_input_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU not support specify memory_format.",
        [
            "linux"
        ]
    ],
    "test_conv_empty_input_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU not support specify memory_format.",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_label_smoothing_consistent_index_target_and_probs_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:46.839.875 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_label_smoothing_weight_ignore_indices_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:46.861.035 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_label_smoothing_with_probs_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_large_tensor_reduction_mean_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_large_tensor_reduction_none_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_large_tensor_reduction_sum_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_index_target_unit_weights_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:47.394.691 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_one_hot_target_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:47.407.258 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_all_reductions_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_mean_weighted_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_mean_weighted_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_none_weighted_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_none_weighted_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_sum_weighted_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_sum_weighted_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_unit_weights_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_ctc_loss_cudnn_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: only npu tensor is supported",
        [
            "linux"
        ]
    ],
    "test_device_mask_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: shape '[5, 5]' is invalid for input of size 12",
        [
            "linux"
        ]
    ],
    "test_elu_inplace_overlap_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_elu_inplace_with_neg_alpha_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: \"call out-of-place version\" does not match \"call aclnnEluBackward failed, detail:EZ1001: 2024-09-11-07:23:47.449.956 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_fold_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnIm2colBackward failed, detail:EZ1001: 2024-09-11-07:23:47.459.089 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_grid_sample_half_precision_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_grid_sample_large_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_grid_sample_large_index_2d_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_grid_sample_large_index_2d_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_grid_sample_large_index_3d_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_grid_sample_large_index_3d_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_grid_sample_nan_inf_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_grid_sample_nan_inf_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_gumbel_softmax_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: tensor(0., device='npu:0', dtype=torch.float16) not greater than or equal to 0",
        [
            "linux"
        ]
    ],
    "test_gumbel_softmax_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: tensor(0., device='npu:0', dtype=torch.float32) not greater than or equal to 0",
        [
            "linux"
        ]
    ],
    "test_gumbel_softmax_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: tensor(0., device='npu:0', dtype=torch.float32) not greater than or equal to 0",
        [
            "linux"
        ]
    ],
    "test_hardsigmoid_grad_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnHardsigmoid failed, detail:EZ1001: 2024-09-11-07:23:48.176.845 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT32,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_hardswish_grad_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnHardswish failed, detail:EZ1001: 2024-09-11-07:23:48.182.706 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_hardswish_inplace_overlap_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: \"unsupported operation\" does not match \"call aclnnInplaceHardswish failed, detail:EZ1001: 2024-09-11-07:23:48.187.737 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_instancenorm_raises_error_for_single_spatial_element_during_training_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnBatchNorm failed, detail:EZ1001: 2024-09-11-07:23:48.192.646 input not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_invalid_reduction_strings_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-11-07:23:48.209.950 self not implemented for DT_COMPLEX64, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_layernorm_half_precision_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not equal!",
        [
            "linux"
        ]
    ],
    "test_layernorm_weight_bias_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_leaky_relu_inplace_overlap_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_leaky_relu_inplace_with_neg_slope_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: \"call out-of-place version\" does not match \"call aclnnLeakyReluBackward failed, detail:EZ1001: 2024-09-11-07:23:48.221.461 In-place leakyRelu backward calculation is triggered with a negativeSlope which is not supported.",
        [
            "linux"
        ]
    ],
    "test_leaky_relu_inplace_with_zero_slope_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_linear_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:23:48.237.390 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_log_softmax_big_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_log_softmax_big_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_logsigmoid_out_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-11-07:23:48.246.772 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_lstmcell_backward_only_one_output_grad_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: True is not false",
        [
            "linux"
        ]
    ],
    "test_masked_softmax_TxT_layout_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_masked_softmax_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNanToNum failed, detail:EZ1001: 2024-09-11-07:23:48.468.685 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_BFLOAT16,DT_INT8,DT_INT16,DT_INT32,DT_INT64,DT_UINT8,DT_BOOL,].",
        [
            "linux"
        ]
    ],
    "test_masked_softmax_devices_parity_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnInplaceMaskedFillScalar failed, detail:EZ1001: 2024-09-11-07:23:48.474.480 selfRef not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_masked_softmax_forward_with_nans_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnInplaceMaskedFillScalar failed, detail:EZ1001: 2024-09-11-07:23:48.481.679 selfRef not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_masked_softmax_grad_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnInplaceMaskedFillScalar failed, detail:EZ1001: 2024-09-11-07:23:48.488.973 selfRef not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_masked_softmax_mask_types_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNanToNum failed, detail:EZ1001: 2024-09-11-07:23:48.496.570 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_BFLOAT16,DT_INT8,DT_INT16,DT_INT32,DT_INT64,DT_UINT8,DT_BOOL,].",
        [
            "linux"
        ]
    ],
    "test_masked_softmax_transformer_layout_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_mish_inplace_overlap_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: \"unsupported operation\" does not match \"call aclnnInplaceMish failed, detail:EZ1001: 2024-09-11-07:23:48.828.127 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_module_to_empty_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnMatmul failed, detail:EZ1001: 2024-09-11-07:23:48.833.996 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_all_ignored_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:48.839.890 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_byte_target_matches_long_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:48.848.464 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_empty_tensor_reduction_mean_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:48.856.257 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_empty_tensor_reduction_none_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:48.864.791 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_empty_tensor_reduction_sum_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:48.873.695 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_invalid_target_dim_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: \"1D target tensor expected\" does not match \"call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:48.882.137 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_invalid_weights_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: \"weight tensor should be defined either for all 3 classes or no classes\" does not match \"call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:48.890.474 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_large_tensor_reduction_mean_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_nll_loss_large_tensor_reduction_none_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_nll_loss_large_tensor_reduction_sum_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_nll_loss_out_of_bounds_ignore_index_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:49.434.855 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_total_weight_is_zero_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:23:49.445.240 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nn_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-11-07:23:49.453.861 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nn_scalars_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnEluBackward failed, detail:EZ1001: 2024-09-11-07:23:49.459.920 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nn_scalars_reductions_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-11-07:23:49.469.273 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nonlinearity_propagate_nan_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnRelu failed, detail:EZ1001: 2024-09-11-07:23:49.474.272 Self dtype DT_DOUBLE should be in dtype support list [[DT_FLOAT,DT_FLOAT16,DT_INT8,DT_UINT8,DT_INT32,DT_INT64,]DT_BF16].",
        [
            "linux"
        ]
    ],
    "test_one_hot_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: The values for attribute 'shape' do not match: torch.Size([4, 1]) != torch.Size([4, 5]).",
        [
            "linux"
        ]
    ],
    "test_overwrite_module_params_on_conversion_cpu_device_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: False is not true",
        [
            "linux"
        ]
    ],
    "test_pad_cuda_complex128 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-11-07:23:49.484.674 self not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_pad_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: \"Padding size should be less than the corresponding input dimension\" does not match \"call aclnnReflectionPad2d failed, detail:EZ1001: 2024-09-11-07:23:49.506.546 padding size should be less than the corresponding self dimention.",
        [
            "linux"
        ]
    ],
    "test_prelu_backward_32bit_indexing_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_rnn_fused_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_rnn_fused_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_rnn_retain_variables_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_rnn_retain_variables_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_rnn_retain_variables_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_smooth_l1_loss_vs_huber_loss_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-11-07:23:49.755.759 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_smoothl1loss_backward_zero_beta_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-11-07:23:49.760.645 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_softmax_64bit_indexing_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_softmax_backward_64bit_indexing_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_softmax_bfloat16_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_softmax_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not equal!",
        [
            "linux"
        ]
    ],
    "test_softmax_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not equal!",
        [
            "linux"
        ]
    ],
    "test_softmax_results_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_softmax_results_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_softplus_low_threshold_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnSoftplus failed, detail:EZ1001: 2024-09-11-07:23:50.144.621 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_softshrink_negative_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: \"lambda must be greater or equal to 0, but found to be -1\\.\" does not match \"lambd should be greater than 0",
        [
            "linux"
        ]
    ],
    "test_threshold_inplace_overlap_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnInplaceThreshold failed, detail:EZ1001: 2024-09-11-07:23:50.158.518 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_FLOAT16,DT_INT8,DT_UINT8,DT_INT16,DT_INT64,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_transformerencoderlayer_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_transformerencoderlayer_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_transformerencoderlayer_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:23:50.175.836 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_transformerencoderlayer_gelu_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_transformerencoderlayer_gelu_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_triplet_margin_with_distance_loss_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-11-07:23:50.189.370 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_triplet_margin_with_distance_loss_default_parity_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-11-07:23:50.196.987 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:23:50.211.470 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bilinear_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bilinear_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:23:50.231.626 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bilinear_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bilinear_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bicubic_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bilinear_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bilinear_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bicubic_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bilinear_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bilinear_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bicubic_float64_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:23:50.529.479 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bilinear_float64_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bicubic_float64_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:23:50.715.564 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bilinear_float64_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_3_mode_bicubic_uint8_cuda_uint8 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_3_mode_bilinear_uint8_cuda_uint8 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_5_mode_bicubic_uint8_cuda_uint8 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_5_mode_bilinear_uint8_cuda_uint8 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_upsamplingBicubic2d_aa_correctness_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBicubic2d_aa_correctness_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBicubic2d_correctness_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:23:51.125.049 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBilinear2d_aa_correctness_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBilinear2d_aa_correctness_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest1d_correctness_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest1d_correctness_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest1d_mode_nearest-exact_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest1d_mode_nearest_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_correctness_memory_format_torch_channels_last_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_correctness_memory_format_torch_channels_last_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_memory_format_torch_channels_last_mode_nearest-exact_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_memory_format_torch_channels_last_mode_nearest_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_memory_format_torch_contiguous_format_mode_nearest-exact_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_memory_format_torch_contiguous_format_mode_nearest_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_correctness_memory_format_torch_channels_last_3d_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_correctness_memory_format_torch_channels_last_3d_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_memory_format_torch_channels_last_3d_mode_nearest-exact_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_memory_format_torch_channels_last_3d_mode_nearest_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest-exact_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: call aclnnUpsampleNearest3d failed, detail:EZ1001: 2024-09-11-07:24:04.798.904 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_DOUBLE,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact1d_correctness_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact1d_correctness_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact1d_rescale_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact2d_correctness_memory_format_torch_channels_last_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact2d_correctness_memory_format_torch_channels_last_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact2d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact2d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact3d_correctness_memory_format_torch_channels_last_3d_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact3d_correctness_memory_format_torch_channels_last_3d_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact3d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact3d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingTrilinear3d_align_corners_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingTrilinear3d_align_corners_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsampling_64bit_indexing_channels_last_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_variable_sequence_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_variable_sequence_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_variable_sequence_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_warp_softmax_64bit_indexing_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_warp_softmax_64bit_indexing_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
        "TypeError: isinstance() arg 2 must be a type or tuple of types",
        [
            "linux"
        ]
    ],
    "test_BatchNorm_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_Bilinear_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_empty_target_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: False is not true",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-11-07:24:05.964.680 DimNum of logProbs [2] must equal 3.",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-11-07:24:05.971.882 DimNum of logProbs [2] must equal 3.",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_no_batch_dim_reduction_none_use_module_form_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-11-07:24:05.978.678 DimNum of logProbs [2] must equal 3.",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_no_batch_dim_reduction_none_use_module_form_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-11-07:24:05.984.918 DimNum of logProbs [2] must equal 3.",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-11-07:24:05.991.226 DimNum of logProbs [2] must equal 3.",
        [
            "linux"
        ]
    ],
    "test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-11-07:24:05.997.735 DimNum of logProbs [2] must equal 3.",
        [
            "linux"
        ]
    ],
    "test_GRU_grad_and_gradgrad_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-11-07:24:06.004.833 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_GroupNorm_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnGroupNorm failed, detail:EZ1001: 2024-09-11-07:24:06.009.898 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_BFLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_GroupNorm_general_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnGroupNorm failed, detail:EZ1001: 2024-09-11-07:24:06.018.914 Expected eps to be greater than 0, got 0.000000.",
        [
            "linux"
        ]
    ],
    "test_GroupNorm_memory_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU not support specify memory_format.",
        [
            "linux"
        ]
    ],
    "test_GroupNorm_numeric_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_InstanceNorm1d_general_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_InstanceNorm2d_general_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_InstanceNorm3d_general_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_LSTM_grad_and_gradgrad_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-11-07:24:06.039.726 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_LayerNorm_general_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_LayerNorm_numeric_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_LocalResponseNorm_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_MarginLoss_empty_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_MarginLoss_empty_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_ReflectionPad_empty_npu_complex64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-11-07:24:06.093.391 self not implemented for DT_COMPLEX64, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_ReflectionPad_empty_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad1d_large_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad2d_large_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad_empty_npu_complex128 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-11-07:24:06.140.530 self not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_ReplicationPad_empty_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_TransformerDecoderLayer_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:24:06.175.827 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_TransformerDecoder_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:24:06.213.377 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_TransformerEncoderLayer_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:24:06.240.778 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_TransformerEncoder_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:24:06.270.774 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_Transformer_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:24:06.778.591 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_Unfold_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnIm2col failed, detail:EZ1001: 2024-09-11-07:24:06.786.969 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_affine_2d_rotate0_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_affine_2d_rotate45_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_affine_2d_rotate90_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_affine_2d_rotateRandom_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_affine_3d_rotateRandom_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_affine_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_eval_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_grad_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnBatchNorm failed, detail:EZ1001: 2024-09-11-07:24:06.806.169 input not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_batchnorm_simple_average_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_batchnorm_update_stats_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not equal!",
        [
            "linux"
        ]
    ],
    "test_channel_shuffle_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not equal!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_error_if_nonfinite_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-11-07:24:06.819.822 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_False_norm_type_0_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_False_norm_type_1_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_False_norm_type_2_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-11-07:24:06.830.470 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_False_norm_type_4_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_False_norm_type_inf_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_True_norm_type_0_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_True_norm_type_1_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_True_norm_type_2_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-11-07:24:06.843.663 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_True_norm_type_4_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_norm_foreach_True_norm_type_inf_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_clip_grad_value_foreach_False_privateuse1 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: tensor(0., device='npu:0') not less than or equal to 2.5",
        [
            "linux"
        ]
    ],
    "test_clip_grad_value_foreach_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: tensor(0., device='npu:0') not less than or equal to 2.5",
        [
            "linux"
        ]
    ],
    "test_conv_empty_input_npu_bfloat16 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU not support specify memory_format.",
        [
            "linux"
        ]
    ],
    "test_conv_empty_input_npu_complex128 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnAdd failed, detail:EZ1001: 2024-09-11-07:24:06.861.893 other not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT16,DT_INT8,DT_UINT8,DT_DOUBLE,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_conv_empty_input_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU not support specify memory_format.",
        [
            "linux"
        ]
    ],
    "test_conv_empty_input_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU not support specify memory_format.",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_label_smoothing_consistent_index_target_and_probs_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:06.877.532 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_label_smoothing_weight_ignore_indices_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:06.898.900 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_label_smoothing_with_probs_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_index_target_unit_weights_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:06.921.776 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_one_hot_target_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:06.945.952 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_all_reductions_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_mean_weighted_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_mean_weighted_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_none_weighted_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_none_weighted_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_sum_weighted_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_sum_weighted_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Scalars are not close!",
        [
            "linux"
        ]
    ],
    "test_cross_entropy_loss_prob_target_unit_weights_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_ctc_loss_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-11-07:24:06.984.201 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_elu_inplace_overlap_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_elu_inplace_with_neg_alpha_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: \"call out-of-place version\" does not match \"call aclnnEluBackward failed, detail:EZ1001: 2024-09-11-07:24:06.991.448 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_fold_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnIm2colBackward failed, detail:EZ1001: 2024-09-11-07:24:07.000.357 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_grid_sample_nan_inf_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_grid_sample_nan_inf_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_gumbel_softmax_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: tensor(0., device='npu:0', dtype=torch.float32) not greater than or equal to 0",
        [
            "linux"
        ]
    ],
    "test_gumbel_softmax_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: tensor(0., device='npu:0', dtype=torch.float32) not greater than or equal to 0",
        [
            "linux"
        ]
    ],
    "test_hardsigmoid_grad_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnHardsigmoid failed, detail:EZ1001: 2024-09-11-07:24:07.019.362 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT32,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_hardswish_grad_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnHardswish failed, detail:EZ1001: 2024-09-11-07:24:07.024.547 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_hardswish_inplace_overlap_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: \"unsupported operation\" does not match \"call aclnnInplaceHardswish failed, detail:EZ1001: 2024-09-11-07:24:07.029.502 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_instancenorm_raises_error_for_single_spatial_element_during_training_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnBatchNorm failed, detail:EZ1001: 2024-09-11-07:24:07.034.221 input not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_invalid_reduction_strings_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-11-07:24:07.050.722 self not implemented for DT_COMPLEX64, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_leaky_relu_inplace_overlap_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_leaky_relu_inplace_with_neg_slope_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: \"call out-of-place version\" does not match \"call aclnnLeakyReluBackward failed, detail:EZ1001: 2024-09-11-07:24:07.059.379 In-place leakyRelu backward calculation is triggered with a negativeSlope which is not supported.",
        [
            "linux"
        ]
    ],
    "test_leaky_relu_inplace_with_zero_slope_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_linear_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-11-07:24:07.076.108 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_log_softmax_big_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_logsigmoid_out_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-11-07:24:07.083.672 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_mish_inplace_overlap_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: \"unsupported operation\" does not match \"call aclnnInplaceMish failed, detail:EZ1001: 2024-09-11-07:24:40.090.995 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_module_to_empty_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnMatmul failed, detail:EZ1001: 2024-09-11-07:24:40.104.165 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_all_ignored_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:40.109.736 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_byte_target_matches_long_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:40.118.132 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_empty_tensor_reduction_mean_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:40.126.282 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_empty_tensor_reduction_none_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:40.134.428 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_empty_tensor_reduction_sum_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:40.142.779 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_invalid_target_dim_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: \"1D target tensor expected\" does not match \"call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:40.151.426 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_invalid_weights_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: \"weight tensor should be defined either for all 3 classes or no classes\" does not match \"call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:40.160.129 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_out_of_bounds_ignore_index_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:40.173.443 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nll_loss_total_weight_is_zero_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-11-07:24:40.181.892 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nn_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-11-07:24:40.190.181 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nn_scalars_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnEluBackward failed, detail:EZ1001: 2024-09-11-07:24:40.196.243 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nn_scalars_reductions_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-11-07:24:40.205.259 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_nonlinearity_propagate_nan_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnRelu failed, detail:EZ1001: 2024-09-11-07:24:40.209.985 Self dtype DT_DOUBLE should be in dtype support list [[DT_FLOAT,DT_FLOAT16,DT_INT8,DT_UINT8,DT_INT32,DT_INT64,]DT_BF16].",
        [
            "linux"
        ]
    ],
    "test_one_hot_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_pad_npu_complex128 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-11-07:24:40.215.844 self not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_pad_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: \"Padding size should be less than the corresponding input dimension\" does not match \"call aclnnReflectionPad2d failed, detail:EZ1001: 2024-09-11-07:24:40.237.583 padding size should be less than the corresponding self dimention.",
        [
            "linux"
        ]
    ],
    "test_rnn_retain_variables_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_smooth_l1_loss_vs_huber_loss_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-11-07:24:40.295.115 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_smoothl1loss_backward_zero_beta_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-11-07:24:40.300.063 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_softmax_bfloat16_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_softmax_results_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_softplus_low_threshold_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnSoftplus failed, detail:EZ1001: 2024-09-11-07:24:40.317.736 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_softshrink_negative_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: \"lambda must be greater or equal to 0, but found to be -1\\.\" does not match \"lambd should be greater than 0",
        [
            "linux"
        ]
    ],
    "test_threshold_inplace_overlap_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnInplaceThreshold failed, detail:EZ1001: 2024-09-11-07:24:40.330.939 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_FLOAT16,DT_INT8,DT_UINT8,DT_INT16,DT_INT64,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_transformerencoderlayer_gelu_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_transformerencoderlayer_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_triplet_margin_with_distance_loss_default_parity_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-11-07:24:40.344.795 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_triplet_margin_with_distance_loss_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-11-07:24:40.354.105 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_channels_last_align_corners_False_input_size_399_output_size_437_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_channels_last_align_corners_False_input_size_403_output_size_377_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_channels_last_align_corners_True_input_size_399_output_size_437_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_channels_last_align_corners_True_input_size_403_output_size_377_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_False_input_size_399_output_size_437_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:40.371.307 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_False_input_size_403_output_size_377_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:40.378.984 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_True_input_size_399_output_size_437_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:40.386.139 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_True_input_size_403_output_size_377_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:40.393.807 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:40.405.229 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bilinear_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bilinear_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:40.426.940 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bilinear_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bilinear_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bicubic_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bilinear_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bilinear_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bicubic_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bilinear_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bilinear_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.482.596 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.490.102 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.498.005 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.506.002 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.524.561 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.532.628 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.540.813 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.548.996 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.556.619 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.564.529 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.572.255 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.580.283 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.589.029 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.596.665 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.604.019 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.611.182 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.619.072 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.627.047 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.635.162 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.643.051 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.651.055 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.659.254 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.668.139 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.676.591 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.684.644 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.692.325 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.700.269 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.708.118 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.716.075 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.724.647 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.733.625 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.741.838 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.834.425 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.842.720 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.851.033 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.858.967 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.866.721 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.874.754 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.883.002 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.890.757 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.898.207 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.906.270 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.913.424 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.921.197 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.939.177 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.947.344 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.955.634 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.964.825 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.972.567 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.980.414 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.988.208 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:41.995.991 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.003.830 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.011.849 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.019.561 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.027.418 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.035.560 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.043.538 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.050.936 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.058.832 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.066.688 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.074.625 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.082.484 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.090.690 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.098.802 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.108.635 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.116.536 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.124.145 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.132.071 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.139.625 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.147.325 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.155.184 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.163.227 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.170.931 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.178.625 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.186.422 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.194.021 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.202.093 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.209.819 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.217.590 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.225.642 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.233.733 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.241.732 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.249.387 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.256.811 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.264.168 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.271.378 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.279.472 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.287.311 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.295.346 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.303.464 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.311.606 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.319.777 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.328.464 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.336.400 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:42.344.490 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: ",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.169.115 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.177.541 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.185.523 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.193.425 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.201.099 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.208.922 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.216.756 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.224.756 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.232.551 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.240.371 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.248.204 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.255.716 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.263.234 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.270.950 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.278.113 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.285.288 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.292.703 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.300.298 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.308.037 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.315.520 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.322.940 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.331.320 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.339.129 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.347.210 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.354.841 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.362.499 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.370.156 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.377.869 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.385.931 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.393.538 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.400.606 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.408.189 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.415.764 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.423.414 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.431.363 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.439.594 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.447.318 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.455.154 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.462.698 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.470.356 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.477.713 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.485.392 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.493.022 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.500.914 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.508.886 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.516.717 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.524.677 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.532.494 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.539.928 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.547.841 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.555.586 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.563.653 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.571.673 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.579.503 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.587.528 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.595.314 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.602.996 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.610.607 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.618.183 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.626.050 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.634.001 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.641.446 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.648.759 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.656.020 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.663.196 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.670.384 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.677.464 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.684.537 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.691.671 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.699.654 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.707.607 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.715.190 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.723.063 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.730.810 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.738.667 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.746.549 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.753.983 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.761.152 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.768.928 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.775.974 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.783.192 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.790.792 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.798.506 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.806.134 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.813.988 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.822.014 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.829.732 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.837.485 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.845.537 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.853.669 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.861.448 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.869.235 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.876.944 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.884.666 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.892.479 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-11-07:24:44.900.321 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bicubic_float64_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:46.296.916 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bilinear_float64_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bicubic_float64_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:46.472.299 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bilinear_float64_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_3_mode_bicubic_uint8_npu_uint8 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_3_mode_bilinear_uint8_npu_uint8 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_5_mode_bicubic_uint8_npu_uint8 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_5_mode_bilinear_uint8_npu_uint8 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: RuntimeError not raised",
        [
            "linux"
        ]
    ],
    "test_upsamplingBicubic2d_aa_correctness_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBicubic2d_aa_correctness_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingBicubic2d_correctness_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-11-07:24:46.901.104 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingBilinear2d_aa_correctness_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingBilinear2d_aa_correctness_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest1d_correctness_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest1d_correctness_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest1d_mode_nearest-exact_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest1d_mode_nearest_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_correctness_memory_format_torch_channels_last_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_correctness_memory_format_torch_channels_last_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_memory_format_torch_channels_last_mode_nearest-exact_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_memory_format_torch_channels_last_mode_nearest_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_memory_format_torch_contiguous_format_mode_nearest-exact_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest2d_memory_format_torch_contiguous_format_mode_nearest_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_correctness_memory_format_torch_channels_last_3d_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_correctness_memory_format_torch_channels_last_3d_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_memory_format_torch_channels_last_3d_mode_nearest-exact_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_memory_format_torch_channels_last_3d_mode_nearest_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest-exact_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: call aclnnUpsampleNearest3d failed, detail:EZ1001: 2024-09-11-07:24:47.132.445 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_DOUBLE,].",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact1d_correctness_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact1d_correctness_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact1d_rescale_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact2d_correctness_memory_format_torch_channels_last_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact2d_correctness_memory_format_torch_channels_last_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact2d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact2d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact3d_correctness_memory_format_torch_channels_last_3d_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact3d_correctness_memory_format_torch_channels_last_3d_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact3d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingNearestExact3d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ],
    "test_upsamplingTrilinear3d_align_corners_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_upsamplingTrilinear3d_align_corners_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "RuntimeError: Comparing",
        [
            "linux"
        ]
    ],
    "test_variable_sequence_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
        "AssertionError: Tensor-likes are not close!",
        [
            "linux"
        ]
    ]
}